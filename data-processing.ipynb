{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from dfply import *\n",
    "import glob\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #first data dump\n",
    "# headerlist = ['timestamp']\n",
    "# for i in range(1,6):\n",
    "#     for j in range(1,257):\n",
    "#         headerlist.append('imf_'+str(i)+'_feature_'+str(j))\n",
    "# files = []\n",
    "# for filepath in glob.iglob(r\"E:\\\\ProjectData\\\\ERAU-REU\\\\Project-Drone-Behavior\\\\behavior-captures\\\\*.csv\"):\n",
    "#     files.append(filepath)\n",
    "\n",
    "# for file in files:\n",
    "#     df = pd.read_csv(file,header=None)\n",
    "#     df.columns = headerlist\n",
    "#     df.to_csv(file,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #extra whitenoise data dump\n",
    "# headerlist = ['timestamp']\n",
    "# for i in range(1,6):\n",
    "#     for j in range(1,257):\n",
    "#         headerlist.append('imf_'+str(i)+'_feature_'+str(j))\n",
    "# files = []\n",
    "# for filepath in glob.iglob(r\"E:\\\\ProjectData\\\\ERAU-REU\\\\Project-Drone-Behavior\\\\extra-whitenoise\\\\*.csv\"):\n",
    "#     files.append(filepath)\n",
    "\n",
    "# for file in files:\n",
    "#     df = pd.read_csv(file,header=None)\n",
    "#     df.columns = headerlist\n",
    "#     df.to_csv(\"E:\\\\ProjectData\\\\ERAU-REU\\\\Project-Drone-Behavior\\\\behavior-captures\\\\\"+file[68:],index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# #creating a labelled and scaled dataset for just the flight behavior\n",
    "# files = []\n",
    "# for filepath in glob.iglob(r\"E:\\\\ProjectData\\\\ERAU-REU\\\\Project-Drone-Behavior\\\\behavior-captures\\\\*.csv\"):\n",
    "#     files.append(filepath)\n",
    "# #feature engineering a new column to act as the output for predictions. This will be the behavior that we want to predict on\n",
    "# first = True\n",
    "# processed = False\n",
    "# for filepath in files:\n",
    "#     processed = False\n",
    "#     if 'processed' in filepath:\n",
    "#         processed = True\n",
    "#         pass\n",
    "#     elif 'straight' in filepath:\n",
    "#         df = pd.read_csv(filepath, skiprows=1)\n",
    "#         df.drop('timestamp',axis=1,inplace=True)\n",
    "#         df['behavior'] = 'straight'\n",
    "#     elif 'surround' in filepath:\n",
    "#         df = pd.read_csv(filepath, skiprows=1)\n",
    "#         df.drop('timestamp',axis=1,inplace=True)\n",
    "#         df['behavior'] = 'surround'\n",
    "#     else:\n",
    "#         df = pd.read_csv(filepath,skiprows=1)\n",
    "#         df.drop('timestamp',axis=1,inplace=True)\n",
    "#         df['behavior'] = 'noise'\n",
    "    \n",
    "#     #create new dataframe and append all to it\n",
    "#     if processed:\n",
    "#         pass\n",
    "#     elif first and not processed:\n",
    "#         newDf = df\n",
    "#         first = False\n",
    "#     else:\n",
    "#         newDf = newDf.append(df,ignore_index=True)\n",
    "# #normalizing the data by center and scale\n",
    "# #causes all of the datapoints to be between 1 and 0 based on their z-score\n",
    "# valuesDf = newDf.drop('behavior',axis=1)\n",
    "# x = valuesDf.values\n",
    "# min_max_scaler = preprocessing.MinMaxScaler()\n",
    "# x_scaled = min_max_scaler.fit_transform(x)\n",
    "# df = pd.DataFrame(x_scaled,columns=valuesDf.columns,index=newDf.index)\n",
    "# df['behavior'] = newDf['behavior']\n",
    "# df.drop_duplicates(inplace=True)\n",
    "# df.to_csv(\"E:\\\\ProjectData\\\\ERAU-REU\\\\Project-Drone-Behavior\\\\behavior-captures\\\\behavior-processed.csv\",index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#creating a labelled and scaled dataset for the additional features of the dataset as well. \n",
    "files = []\n",
    "for filepath in glob.iglob(r\"E:\\\\ProjectData\\\\ERAU-REU\\\\Project-Drone-Behavior\\\\behavior-captures\\\\*.csv\"):\n",
    "    files.append(filepath)\n",
    "#feature engineering a new column to act as the output for predictions. This will be the behavior that we want to predict on\n",
    "first = True\n",
    "processed = False\n",
    "for filepath in files:\n",
    "    first_char = filepath[69].lower()\n",
    "    processed = False\n",
    "    if 'processed' in filepath:\n",
    "        processed = True\n",
    "        pass\n",
    "    elif 'straight' in filepath and first_char == 'c':\n",
    "        df = pd.read_csv(filepath)\n",
    "        df.drop('timestamp',axis=1,inplace=True)\n",
    "        df['behavior'] = 'straight'\n",
    "        df['signal'] = 'controller'\n",
    "    elif 'straight' in filepath and first_char == 'v':\n",
    "        df = pd.read_csv(filepath)\n",
    "        df.drop('timestamp',axis=1,inplace=True)\n",
    "        df['behavior'] = 'straight'\n",
    "        df['signal'] = 'video'\n",
    "    elif 'surround' in filepath and first_char == 'c':\n",
    "        df = pd.read_csv(filepath)\n",
    "        df.drop('timestamp',axis=1,inplace=True)\n",
    "        df['behavior'] = 'surround'\n",
    "        df['signal'] = 'controller'\n",
    "    elif 'surround' in filepath and first_char == 'v':\n",
    "        df = pd.read_csv(filepath)\n",
    "        df.drop('timestamp',axis=1,inplace=True)\n",
    "        df['behavior'] = 'surround'\n",
    "        df['signal'] = 'video'\n",
    "    else:\n",
    "        df = pd.read_csv(filepath)\n",
    "        df.drop('timestamp',axis=1,inplace=True)\n",
    "        df['behavior'] = 'noise'\n",
    "        df['signal'] = 'none'\n",
    "    if processed:\n",
    "        pass\n",
    "    elif 'green' in filepath and 'yellow' in filepath:\n",
    "        df['multiple'] = 1\n",
    "    else:\n",
    "        df['multiple'] = 0 \n",
    "    #create new dataframe and append all to it\n",
    "    if processed:\n",
    "        pass\n",
    "    elif first and not processed:\n",
    "        newDf = df\n",
    "        first = False\n",
    "    else:\n",
    "        newDf = newDf.append(df,ignore_index=True)\n",
    "#normalizing the data by center and scale\n",
    "#causes all of the datapoints to be between 1 and 0 based on their z-score\n",
    "valuesDf = newDf.drop(['behavior','signal','multiple'],axis=1)\n",
    "x = valuesDf.values\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(x)\n",
    "df = pd.DataFrame(x_scaled,columns=valuesDf.columns,index=newDf.index)\n",
    "df['behavior'] = newDf['behavior']\n",
    "df['signal'] = newDf['signal']\n",
    "df['multiple'] = newDf['multiple']\n",
    "df.drop_duplicates(inplace=True)\n",
    " \n",
    "df.to_csv(\"E:\\\\ProjectData\\\\ERAU-REU\\\\Project-Drone-Behavior\\\\behavior-captures\\\\behavior-signal-multiple-processed.csv\",index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit ('tfgpu': conda)",
   "language": "python",
   "name": "python37764bittfgpuconda45a37ab07269429dbc68acdce435ee9a"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}