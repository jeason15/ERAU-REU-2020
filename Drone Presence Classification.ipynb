{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"vc.ipynb","provenance":[{"file_id":"18v2kvZmZVP3DC5J7bWdQfzv1H0MGMihB","timestamp":1590624900411}],"machine_shape":"hm","authorship_tag":"ABX9TyOyJIldS9rOP7Lmh3D7C0+t"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"Yv5I5GpJN3Pu","colab_type":"code","outputId":"6f86b548-03d0-4d32-acd0-aed78babac26","executionInfo":{"status":"ok","timestamp":1590729586057,"user_tz":240,"elapsed":17026,"user":{"displayName":"Lennon Chen","photoUrl":"","userId":"13862195579520938405"}},"colab":{"base_uri":"https://localhost:8080/","height":124}},"source":["import pandas as pd\n","import scipy\n","from scipy import io\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","import pandas as pd\n","import scipy\n","from scipy import io\n","import numpy as np"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"oX0qQOYiL51D","colab_type":"code","colab":{}},"source":["drone9 = scipy.io.loadmat('drive/My Drive/SongLab/data/New_Data/v1green_surround_2_RX1.mat')\n","features = drone9['matrix']\n","v1 = pd.DataFrame(features)\n","\n","drone10 = scipy.io.loadmat('drive/My Drive/SongLab/data/New_Data/v1green_surround_2_RX2.mat')\n","features = drone10['matrix']\n","v2 = pd.DataFrame(features)\n","\n","drone11 = scipy.io.loadmat('drive/My Drive/SongLab/data/New_Data/v1green_surround_RX1.mat')\n","features = drone11['matrix']\n","v3 = pd.DataFrame(features)\n","\n","drone12 = scipy.io.loadmat('drive/My Drive/SongLab/data/New_Data/v1green_surround_RX2.mat')\n","features = drone12['matrix']\n","v4 = pd.DataFrame(features)\n","\n","drone21 = scipy.io.loadmat('drive/My Drive/SongLab/data/New_Data/v1green_straight_2_RX1.mat')\n","features = drone21['matrix']\n","v5 = pd.DataFrame(features)\n","\n","drone22 = scipy.io.loadmat('drive/My Drive/SongLab/data/New_Data/v1green_straight_2_RX2.mat')\n","features = drone22['matrix']\n","v6 = pd.DataFrame(features)\n","\n","drone23 = scipy.io.loadmat('drive/My Drive/SongLab/data/New_Data/v1green_straight_RX1.mat')\n","features = drone23['matrix']\n","v7 = pd.DataFrame(features)\n","\n","drone24 = scipy.io.loadmat('drive/My Drive/SongLab/data/New_Data/v1green_straight_RX2.mat')\n","features = drone24['matrix']\n","v8 = pd.DataFrame(features)\n","\n","########################################################################\n","\n","drone1 = scipy.io.loadmat('drive/My Drive/SongLab/data/New_Data/c1yellow_surround_2_RX1.mat')\n","features = drone1['matrix']\n","c1 = pd.DataFrame(features)\n","\n","drone2 = scipy.io.loadmat('drive/My Drive/SongLab/data/New_Data/c1yellow_surround_2_RX2.mat')\n","features = drone2['matrix']\n","c2 = pd.DataFrame(features)\n","\n","drone3 = scipy.io.loadmat('drive/My Drive/SongLab/data/New_Data/c1yellow_surround_RX2.mat')\n","features = drone3['matrix']\n","c3 = pd.DataFrame(features)\n","\n","drone4 = scipy.io.loadmat('drive/My Drive/SongLab/data/New_Data/c2yellow_green_surroud_2_RX1.mat')\n","features = drone4['matrix']\n","c4 = pd.DataFrame(features)\n","\n","drone5 = scipy.io.loadmat('drive/My Drive/SongLab/data/New_Data/c2yellow_green_surroud_2_RX2.mat')\n","features = drone5['matrix']\n","c5 = pd.DataFrame(features)\n","\n","drone6 = scipy.io.loadmat('drive/My Drive/SongLab/data/New_Data/c2yellow_green_surroud_RX1.mat')\n","features = drone6['matrix']\n","c6 = pd.DataFrame(features)\n","\n","drone7 = scipy.io.loadmat('drive/My Drive/SongLab/data/New_Data/c2yellow_green_surroud_RX1.mat')\n","features = drone7['matrix']\n","c7 = pd.DataFrame(features)\n","\n","drone8 = scipy.io.loadmat('drive/My Drive/SongLab/data/New_Data/c2yellow_green_surroud_RX2.mat')\n","features = drone8['matrix']\n","c8 = pd.DataFrame(features)\n","\n","##############################################################################################\n","drone13 = scipy.io.loadmat('drive/My Drive/SongLab/data/New_Data/c1yellow_straight_2_RX1.mat')\n","features = drone13['matrix']\n","c9 = pd.DataFrame(features)\n","\n","drone14 = scipy.io.loadmat('drive/My Drive/SongLab/data/New_Data/c1yellow_straight_2_RX2.mat')\n","features = drone14['matrix']\n","c10 = pd.DataFrame(features)\n","\n","drone15 = scipy.io.loadmat('drive/My Drive/SongLab/data/New_Data/c1yellow_straight_RX1.mat')\n","features = drone15['matrix']\n","c11 = pd.DataFrame(features)\n","\n","drone16 = scipy.io.loadmat('drive/My Drive/SongLab/data/New_Data/c1yellow_straight_RX2.mat')\n","features = drone16['matrix']\n","c12 = pd.DataFrame(features)\n","\n","drone17 = scipy.io.loadmat('drive/My Drive/SongLab/data/New_Data/c2yellow_green_straight_2_RX1.mat')\n","features = drone17['matrix']\n","c13 = pd.DataFrame(features)\n","\n","drone18 = scipy.io.loadmat('drive/My Drive/SongLab/data/New_Data/c2yellow_green_straight_2_RX2.mat')\n","features = drone18['matrix']\n","c14 = pd.DataFrame(features)\n","\n","drone19 = scipy.io.loadmat('drive/My Drive/SongLab/data/New_Data/c2yellow_green_straight_RX1.mat')\n","features = drone19['matrix']\n","c15 = pd.DataFrame(features)\n","\n","drone20 = scipy.io.loadmat('drive/My Drive/SongLab/data/New_Data/c2yellow_green_straight_RX2.mat')\n","features = drone20['matrix']\n","c16 = pd.DataFrame(features)\n","\n","############################################################\n","drone25 = scipy.io.loadmat('drive/My Drive/SongLab/data/New_Data/whitenoise_8332_4096.mat')\n","features = drone25['n']\n","none1 = pd.DataFrame(features)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"DUiKMblsoz5N","colab_type":"code","colab":{}},"source":["drone19 = scipy.io.loadmat('drive/My Drive/SongLab/data/New_Data/c2yellow_green_straight_RX1.mat')\n","features = drone19['matrix']\n","c15 = pd.DataFrame(features)\n","\n","drone20 = scipy.io.loadmat('drive/My Drive/SongLab/data/New_Data/c2yellow_green_straight_RX2.mat')\n","features = drone20['matrix']\n","c16 = pd.DataFrame(features)\n","\n","############################################################\n","drone25 = scipy.io.loadmat('drive/My Drive/SongLab/data/New_Data/whitenoise_8332_4096.mat')\n","features = drone25['n']\n","none1 = pd.DataFrame(features)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7YQN4XhDMnU_","colab_type":"code","colab":{}},"source":["def stack(a,b):\n","  c = np.vstack((a,b))\n","  return c\n","\n","c = stack(c1,c2)\n","c = stack(c,c3)\n","c = stack(c,c4)\n","c = stack(c,c5)\n","c = stack(c,c6)\n","c = stack(c,c7)\n","c = stack(c,c8)\n","c = stack(c,c9)\n","c = stack(c,c10)\n","c = stack(c,c11)\n","c = stack(c,c12)\n","c = stack(c,c13)\n","c = stack(c,c14)\n","c = stack(c,c15)\n","c = stack(c,c16)\n","\n","##############################################\n","\n","v = stack(v1,v2)\n","v = stack(v,v3)\n","v = stack(v,v4)\n","v = stack(v,v5)\n","v = stack(v,v6)\n","v = stack(v,v7)\n","v = stack(v,v8)\n","\n","#################################################\n","#none1\n","\n","##########################################\n","#label of none = 0, label of control = 1, label of vedio = 2\n","y0 = np.zeros((none1.shape[0],1)).astype(int)\n","y1 = np.ones((c.shape[0],1)).astype(int)\n","y2 = 2 * np.ones((v.shape[0],1)).astype(int)\n","\n","##########################\n","d0 = np.hstack((none1,y0))\n","d1 = np.hstack((c,y1))\n","d2 = np.hstack((v,y2))\n","\n","d = np.vstack((d0,d1))\n","d = np.vstack((d,d2))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"aLClnkMw4bAD","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"d7e53822-55b1-4425-aec9-f2e931f035b1","executionInfo":{"status":"ok","timestamp":1590729757816,"user_tz":240,"elapsed":376,"user":{"displayName":"Lennon Chen","photoUrl":"","userId":"13862195579520938405"}}},"source":["d.shape"],"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(108316, 4097)"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"3zXMfP6SOTGS","colab_type":"code","colab":{}},"source":["np.random.shuffle(d)\n","\n","x = d[:,0:-1]\n","y = d[:,-1].astype(int)\n","\n","from sklearn.model_selection import train_test_split\n","\n","x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3)\n","#x_train = x_train[:,0:-1]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"G9SS-t6yoSgy","colab_type":"code","colab":{}},"source":["from sklearn.preprocessing import StandardScaler,MinMaxScaler\n","x_train = MinMaxScaler().fit_transform(x_train)\n","x_test = MinMaxScaler().fit_transform(x_test)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"YSkgrMIeDaF1","colab_type":"code","colab":{}},"source":["import torch \n","import torch.nn as nn\n","import torchvision\n","import torchvision.transforms as transforms\n","from torch.utils import data"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zjgAOEwvDeZe","colab_type":"code","colab":{}},"source":["# Device configuration\n","device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","x_train1 = torch.from_numpy(x_train.copy().reshape(-1,4,32,32)).to(device=device, dtype=torch.float)\n","x_test1 = torch.from_numpy(x_test.copy().reshape(-1,4,32,32)).to(device=device, dtype=torch.float)\n","y_train1 = torch.from_numpy(y_train)\n","y_test1 = torch.from_numpy(y_test)\n","\n","\n","batch_size = 256\n","\n","train_dataset = data.TensorDataset(x_train1,y_train1)\n","test_dataset = data.TensorDataset(x_test1,y_test1)\n","train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n","                                           batch_size=batch_size, shuffle=True)\n","\n","test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n","                                          batch_size=batch_size, \n","                                          shuffle=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XJxCGj8C0s7S","colab_type":"code","outputId":"11ee37fb-c571-4151-d833-8f955fca3449","executionInfo":{"status":"ok","timestamp":1590712008000,"user_tz":240,"elapsed":1075,"user":{"displayName":"Lennon Chen","photoUrl":"","userId":"13862195579520938405"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["x_train1.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([75821, 4, 32, 32])"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"code","metadata":{"id":"RxRlEz4nDub1","colab_type":"code","outputId":"aa659213-b878-401d-d0b3-2b8b65d314c6","executionInfo":{"status":"ok","timestamp":1590730028746,"user_tz":240,"elapsed":54668,"user":{"displayName":"Lennon Chen","photoUrl":"","userId":"13862195579520938405"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["# Hyper parameters\n","num_epochs = 20\n","num_classes = 3\n","learning_rate = 0.0025\n","\n","\n","\n","# Convolutional neural network (two convolutional layers)\n","class ConvNet(nn.Module):\n","    def __init__(self, num_classes=3):\n","        super(ConvNet, self).__init__()\n","        self.layer1 = nn.Sequential(\n","            nn.Conv2d(4, 8, kernel_size=3,padding=1, stride=2),\n","            nn.BatchNorm2d(8),\n","            nn.ReLU()\n","            )\n","#            nn.MaxPool2d(kernel_size=2, stride=2))\n","        self.layer2 = nn.Sequential(\n","            nn.Conv2d(8, 16, kernel_size=4,stride=2, padding=0),#, stride=2, padding=1\n","            nn.BatchNorm2d(16),\n","            nn.ReLU()\n","            )\n","        self.layer3 = nn.Sequential(\n","            nn.Conv2d(16, 32, kernel_size=3, stride=2, padding=0),\n","            nn.BatchNorm2d(32),\n","            nn.ReLU(),\n","            #nn.AvgPool2d(kernel_size=2, stride=0)\n","            #nn.MaxPool2d(3)\n","            )\n","        self.layer4 = nn.Sequential(\n","            nn.Conv2d(32, 64, kernel_size=3),\n","            nn.BatchNorm2d(64),\n","            nn.ReLU(),\n","#            nn.MaxPool2d(kernel_size=2, stride=1)\n","            )\n","#            nn.MaxPool2d(kernel_size=2, stride=2))\n","#        self.fc = nn.Linear(1*1*20, num_classes)\n","        self.fc= nn.Sequential(\n","            nn.Linear(64, 32),\n","            #nn.Dropout(p=0.2),\n","            nn.ReLU(),\n","            \n","#            nn.ReLU(),\n","            nn.Linear(32,3),\n","            )\n","        \n","    def forward(self, x):\n","        out = self.layer1(x)\n","        out = self.layer2(out)\n","        out = self.layer3(out)\n","        out = self.layer4(out)\n","        #print(out.shape)\n","        out = out.reshape(out.size(0), -1)\n","        #print(out.shape)\n","        out = self.fc(out)\n","        return out\n","\n","model = ConvNet(num_classes).to(device)\n","\n","# Loss and optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","#optimizer = torch.optim.Adagrad(model.parameters(), lr=learning_rate)\n","\n","\n","# Train the model\n","total_step = len(train_loader)\n","for epoch in range(num_epochs):\n","    for i, (images, labels) in enumerate(train_loader):\n","        images = images.to(device)\n","        labels = labels.view(-1).to(device)\n","        \n","        # Forward pass\n","        outputs = model(images)\n","#        loss = criterion(outputs, torch.max(labels, 1)[1])\n","        loss = criterion(outputs, labels)\n","        # Backward and optimize\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","        \n","        if (i+1) % 10 == 0:\n","            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n","                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n","\n","# Test the model\n","#model.eval()  # eval mode (batchnorm uses moving mean/variance instead of mini-batch mean/variance)\n","with torch.no_grad():\n","  correct = 0\n","  total = 0\n","    #kk=0\n","  for images, labels in test_loader:\n","     # kk=kk+1\n","    images = images.to(device)\n","    labels = labels.to(device)\n","    outputs = model(images)\n","    _, predicted = torch.max(outputs.data, 1)\n","    total += labels.size(0)\n","    correct += (predicted == labels.view(-1)).sum().item()\n","      #print(kk)\n","\n","  print('Test Accuracy of the model on the test images: {} %'.format(100 * correct / total))\n","\n","# Save the model checkpoint\n","#torch.save(model.state_dict(), 'model.ckpt')"],"execution_count":11,"outputs":[{"output_type":"stream","text":["Epoch [1/20], Step [10/297], Loss: 0.4994\n","Epoch [1/20], Step [20/297], Loss: 0.1992\n","Epoch [1/20], Step [30/297], Loss: 0.1295\n","Epoch [1/20], Step [40/297], Loss: 0.1165\n","Epoch [1/20], Step [50/297], Loss: 0.1092\n","Epoch [1/20], Step [60/297], Loss: 0.1139\n","Epoch [1/20], Step [70/297], Loss: 0.1380\n","Epoch [1/20], Step [80/297], Loss: 0.1137\n","Epoch [1/20], Step [90/297], Loss: 0.1444\n","Epoch [1/20], Step [100/297], Loss: 0.1232\n","Epoch [1/20], Step [110/297], Loss: 0.1374\n","Epoch [1/20], Step [120/297], Loss: 0.1304\n","Epoch [1/20], Step [130/297], Loss: 0.0978\n","Epoch [1/20], Step [140/297], Loss: 0.1600\n","Epoch [1/20], Step [150/297], Loss: 0.0589\n","Epoch [1/20], Step [160/297], Loss: 0.1359\n","Epoch [1/20], Step [170/297], Loss: 0.0783\n","Epoch [1/20], Step [180/297], Loss: 0.0853\n","Epoch [1/20], Step [190/297], Loss: 0.0680\n","Epoch [1/20], Step [200/297], Loss: 0.1039\n","Epoch [1/20], Step [210/297], Loss: 0.0839\n","Epoch [1/20], Step [220/297], Loss: 0.0954\n","Epoch [1/20], Step [230/297], Loss: 0.0615\n","Epoch [1/20], Step [240/297], Loss: 0.1310\n","Epoch [1/20], Step [250/297], Loss: 0.0428\n","Epoch [1/20], Step [260/297], Loss: 0.1258\n","Epoch [1/20], Step [270/297], Loss: 0.0984\n","Epoch [1/20], Step [280/297], Loss: 0.0409\n","Epoch [1/20], Step [290/297], Loss: 0.1253\n","Epoch [2/20], Step [10/297], Loss: 0.0390\n","Epoch [2/20], Step [20/297], Loss: 0.0695\n","Epoch [2/20], Step [30/297], Loss: 0.0805\n","Epoch [2/20], Step [40/297], Loss: 0.0843\n","Epoch [2/20], Step [50/297], Loss: 0.0790\n","Epoch [2/20], Step [60/297], Loss: 0.0948\n","Epoch [2/20], Step [70/297], Loss: 0.0858\n","Epoch [2/20], Step [80/297], Loss: 0.0769\n","Epoch [2/20], Step [90/297], Loss: 0.0574\n","Epoch [2/20], Step [100/297], Loss: 0.0743\n","Epoch [2/20], Step [110/297], Loss: 0.0672\n","Epoch [2/20], Step [120/297], Loss: 0.0994\n","Epoch [2/20], Step [130/297], Loss: 0.0423\n","Epoch [2/20], Step [140/297], Loss: 0.0626\n","Epoch [2/20], Step [150/297], Loss: 0.0966\n","Epoch [2/20], Step [160/297], Loss: 0.0697\n","Epoch [2/20], Step [170/297], Loss: 0.1133\n","Epoch [2/20], Step [180/297], Loss: 0.1036\n","Epoch [2/20], Step [190/297], Loss: 0.1218\n","Epoch [2/20], Step [200/297], Loss: 0.0661\n","Epoch [2/20], Step [210/297], Loss: 0.0917\n","Epoch [2/20], Step [220/297], Loss: 0.0512\n","Epoch [2/20], Step [230/297], Loss: 0.1111\n","Epoch [2/20], Step [240/297], Loss: 0.0878\n","Epoch [2/20], Step [250/297], Loss: 0.0251\n","Epoch [2/20], Step [260/297], Loss: 0.0772\n","Epoch [2/20], Step [270/297], Loss: 0.0549\n","Epoch [2/20], Step [280/297], Loss: 0.0996\n","Epoch [2/20], Step [290/297], Loss: 0.0855\n","Epoch [3/20], Step [10/297], Loss: 0.0962\n","Epoch [3/20], Step [20/297], Loss: 0.0601\n","Epoch [3/20], Step [30/297], Loss: 0.0488\n","Epoch [3/20], Step [40/297], Loss: 0.0783\n","Epoch [3/20], Step [50/297], Loss: 0.0833\n","Epoch [3/20], Step [60/297], Loss: 0.0658\n","Epoch [3/20], Step [70/297], Loss: 0.0881\n","Epoch [3/20], Step [80/297], Loss: 0.0748\n","Epoch [3/20], Step [90/297], Loss: 0.0853\n","Epoch [3/20], Step [100/297], Loss: 0.1748\n","Epoch [3/20], Step [110/297], Loss: 0.0639\n","Epoch [3/20], Step [120/297], Loss: 0.0633\n","Epoch [3/20], Step [130/297], Loss: 0.0616\n","Epoch [3/20], Step [140/297], Loss: 0.0805\n","Epoch [3/20], Step [150/297], Loss: 0.0866\n","Epoch [3/20], Step [160/297], Loss: 0.0949\n","Epoch [3/20], Step [170/297], Loss: 0.0641\n","Epoch [3/20], Step [180/297], Loss: 0.0982\n","Epoch [3/20], Step [190/297], Loss: 0.0645\n","Epoch [3/20], Step [200/297], Loss: 0.0977\n","Epoch [3/20], Step [210/297], Loss: 0.0847\n","Epoch [3/20], Step [220/297], Loss: 0.0774\n","Epoch [3/20], Step [230/297], Loss: 0.0501\n","Epoch [3/20], Step [240/297], Loss: 0.1031\n","Epoch [3/20], Step [250/297], Loss: 0.0804\n","Epoch [3/20], Step [260/297], Loss: 0.0782\n","Epoch [3/20], Step [270/297], Loss: 0.0610\n","Epoch [3/20], Step [280/297], Loss: 0.1214\n","Epoch [3/20], Step [290/297], Loss: 0.0911\n","Epoch [4/20], Step [10/297], Loss: 0.0864\n","Epoch [4/20], Step [20/297], Loss: 0.0669\n","Epoch [4/20], Step [30/297], Loss: 0.0504\n","Epoch [4/20], Step [40/297], Loss: 0.0553\n","Epoch [4/20], Step [50/297], Loss: 0.0712\n","Epoch [4/20], Step [60/297], Loss: 0.0736\n","Epoch [4/20], Step [70/297], Loss: 0.0568\n","Epoch [4/20], Step [80/297], Loss: 0.0836\n","Epoch [4/20], Step [90/297], Loss: 0.0851\n","Epoch [4/20], Step [100/297], Loss: 0.0695\n","Epoch [4/20], Step [110/297], Loss: 0.0514\n","Epoch [4/20], Step [120/297], Loss: 0.0788\n","Epoch [4/20], Step [130/297], Loss: 0.0702\n","Epoch [4/20], Step [140/297], Loss: 0.0910\n","Epoch [4/20], Step [150/297], Loss: 0.1422\n","Epoch [4/20], Step [160/297], Loss: 0.1289\n","Epoch [4/20], Step [170/297], Loss: 0.0598\n","Epoch [4/20], Step [180/297], Loss: 0.1124\n","Epoch [4/20], Step [190/297], Loss: 0.0701\n","Epoch [4/20], Step [200/297], Loss: 0.0714\n","Epoch [4/20], Step [210/297], Loss: 0.0365\n","Epoch [4/20], Step [220/297], Loss: 0.0692\n","Epoch [4/20], Step [230/297], Loss: 0.0540\n","Epoch [4/20], Step [240/297], Loss: 0.1185\n","Epoch [4/20], Step [250/297], Loss: 0.0949\n","Epoch [4/20], Step [260/297], Loss: 0.0649\n","Epoch [4/20], Step [270/297], Loss: 0.0711\n","Epoch [4/20], Step [280/297], Loss: 0.0401\n","Epoch [4/20], Step [290/297], Loss: 0.0855\n","Epoch [5/20], Step [10/297], Loss: 0.0780\n","Epoch [5/20], Step [20/297], Loss: 0.0848\n","Epoch [5/20], Step [30/297], Loss: 0.0696\n","Epoch [5/20], Step [40/297], Loss: 0.0867\n","Epoch [5/20], Step [50/297], Loss: 0.0626\n","Epoch [5/20], Step [60/297], Loss: 0.0855\n","Epoch [5/20], Step [70/297], Loss: 0.0941\n","Epoch [5/20], Step [80/297], Loss: 0.0653\n","Epoch [5/20], Step [90/297], Loss: 0.0532\n","Epoch [5/20], Step [100/297], Loss: 0.0806\n","Epoch [5/20], Step [110/297], Loss: 0.0647\n","Epoch [5/20], Step [120/297], Loss: 0.1170\n","Epoch [5/20], Step [130/297], Loss: 0.0447\n","Epoch [5/20], Step [140/297], Loss: 0.0590\n","Epoch [5/20], Step [150/297], Loss: 0.0537\n","Epoch [5/20], Step [160/297], Loss: 0.0739\n","Epoch [5/20], Step [170/297], Loss: 0.0881\n","Epoch [5/20], Step [180/297], Loss: 0.0873\n","Epoch [5/20], Step [190/297], Loss: 0.0616\n","Epoch [5/20], Step [200/297], Loss: 0.0683\n","Epoch [5/20], Step [210/297], Loss: 0.0579\n","Epoch [5/20], Step [220/297], Loss: 0.1041\n","Epoch [5/20], Step [230/297], Loss: 0.0758\n","Epoch [5/20], Step [240/297], Loss: 0.0741\n","Epoch [5/20], Step [250/297], Loss: 0.0436\n","Epoch [5/20], Step [260/297], Loss: 0.0908\n","Epoch [5/20], Step [270/297], Loss: 0.0677\n","Epoch [5/20], Step [280/297], Loss: 0.0916\n","Epoch [5/20], Step [290/297], Loss: 0.0751\n","Epoch [6/20], Step [10/297], Loss: 0.0508\n","Epoch [6/20], Step [20/297], Loss: 0.0905\n","Epoch [6/20], Step [30/297], Loss: 0.0981\n","Epoch [6/20], Step [40/297], Loss: 0.0798\n","Epoch [6/20], Step [50/297], Loss: 0.0429\n","Epoch [6/20], Step [60/297], Loss: 0.1041\n","Epoch [6/20], Step [70/297], Loss: 0.1058\n","Epoch [6/20], Step [80/297], Loss: 0.0829\n","Epoch [6/20], Step [90/297], Loss: 0.0900\n","Epoch [6/20], Step [100/297], Loss: 0.0687\n","Epoch [6/20], Step [110/297], Loss: 0.0867\n","Epoch [6/20], Step [120/297], Loss: 0.0855\n","Epoch [6/20], Step [130/297], Loss: 0.0733\n","Epoch [6/20], Step [140/297], Loss: 0.0680\n","Epoch [6/20], Step [150/297], Loss: 0.0689\n","Epoch [6/20], Step [160/297], Loss: 0.0873\n","Epoch [6/20], Step [170/297], Loss: 0.0646\n","Epoch [6/20], Step [180/297], Loss: 0.0414\n","Epoch [6/20], Step [190/297], Loss: 0.0700\n","Epoch [6/20], Step [200/297], Loss: 0.1003\n","Epoch [6/20], Step [210/297], Loss: 0.0748\n","Epoch [6/20], Step [220/297], Loss: 0.0834\n","Epoch [6/20], Step [230/297], Loss: 0.0598\n","Epoch [6/20], Step [240/297], Loss: 0.0715\n","Epoch [6/20], Step [250/297], Loss: 0.0395\n","Epoch [6/20], Step [260/297], Loss: 0.0443\n","Epoch [6/20], Step [270/297], Loss: 0.0617\n","Epoch [6/20], Step [280/297], Loss: 0.0601\n","Epoch [6/20], Step [290/297], Loss: 0.0559\n","Epoch [7/20], Step [10/297], Loss: 0.0565\n","Epoch [7/20], Step [20/297], Loss: 0.1025\n","Epoch [7/20], Step [30/297], Loss: 0.0638\n","Epoch [7/20], Step [40/297], Loss: 0.0718\n","Epoch [7/20], Step [50/297], Loss: 0.0793\n","Epoch [7/20], Step [60/297], Loss: 0.0415\n","Epoch [7/20], Step [70/297], Loss: 0.0727\n","Epoch [7/20], Step [80/297], Loss: 0.0665\n","Epoch [7/20], Step [90/297], Loss: 0.1061\n","Epoch [7/20], Step [100/297], Loss: 0.0703\n","Epoch [7/20], Step [110/297], Loss: 0.0986\n","Epoch [7/20], Step [120/297], Loss: 0.0657\n","Epoch [7/20], Step [130/297], Loss: 0.0543\n","Epoch [7/20], Step [140/297], Loss: 0.0863\n","Epoch [7/20], Step [150/297], Loss: 0.0871\n","Epoch [7/20], Step [160/297], Loss: 0.0867\n","Epoch [7/20], Step [170/297], Loss: 0.0762\n","Epoch [7/20], Step [180/297], Loss: 0.0823\n","Epoch [7/20], Step [190/297], Loss: 0.0558\n","Epoch [7/20], Step [200/297], Loss: 0.0706\n","Epoch [7/20], Step [210/297], Loss: 0.0859\n","Epoch [7/20], Step [220/297], Loss: 0.1041\n","Epoch [7/20], Step [230/297], Loss: 0.1241\n","Epoch [7/20], Step [240/297], Loss: 0.0639\n","Epoch [7/20], Step [250/297], Loss: 0.0531\n","Epoch [7/20], Step [260/297], Loss: 0.1096\n","Epoch [7/20], Step [270/297], Loss: 0.0865\n","Epoch [7/20], Step [280/297], Loss: 0.0768\n","Epoch [7/20], Step [290/297], Loss: 0.0547\n","Epoch [8/20], Step [10/297], Loss: 0.1054\n","Epoch [8/20], Step [20/297], Loss: 0.0437\n","Epoch [8/20], Step [30/297], Loss: 0.0437\n","Epoch [8/20], Step [40/297], Loss: 0.0671\n","Epoch [8/20], Step [50/297], Loss: 0.0839\n","Epoch [8/20], Step [60/297], Loss: 0.0755\n","Epoch [8/20], Step [70/297], Loss: 0.0513\n","Epoch [8/20], Step [80/297], Loss: 0.0748\n","Epoch [8/20], Step [90/297], Loss: 0.0872\n","Epoch [8/20], Step [100/297], Loss: 0.0973\n","Epoch [8/20], Step [110/297], Loss: 0.0741\n","Epoch [8/20], Step [120/297], Loss: 0.0729\n","Epoch [8/20], Step [130/297], Loss: 0.0737\n","Epoch [8/20], Step [140/297], Loss: 0.0718\n","Epoch [8/20], Step [150/297], Loss: 0.0949\n","Epoch [8/20], Step [160/297], Loss: 0.0785\n","Epoch [8/20], Step [170/297], Loss: 0.0656\n","Epoch [8/20], Step [180/297], Loss: 0.0543\n","Epoch [8/20], Step [190/297], Loss: 0.1101\n","Epoch [8/20], Step [200/297], Loss: 0.0281\n","Epoch [8/20], Step [210/297], Loss: 0.0346\n","Epoch [8/20], Step [220/297], Loss: 0.0933\n","Epoch [8/20], Step [230/297], Loss: 0.0799\n","Epoch [8/20], Step [240/297], Loss: 0.0941\n","Epoch [8/20], Step [250/297], Loss: 0.0543\n","Epoch [8/20], Step [260/297], Loss: 0.0248\n","Epoch [8/20], Step [270/297], Loss: 0.1032\n","Epoch [8/20], Step [280/297], Loss: 0.0812\n","Epoch [8/20], Step [290/297], Loss: 0.0329\n","Epoch [9/20], Step [10/297], Loss: 0.0481\n","Epoch [9/20], Step [20/297], Loss: 0.0561\n","Epoch [9/20], Step [30/297], Loss: 0.0865\n","Epoch [9/20], Step [40/297], Loss: 0.0819\n","Epoch [9/20], Step [50/297], Loss: 0.0662\n","Epoch [9/20], Step [60/297], Loss: 0.0595\n","Epoch [9/20], Step [70/297], Loss: 0.0788\n","Epoch [9/20], Step [80/297], Loss: 0.0853\n","Epoch [9/20], Step [90/297], Loss: 0.0505\n","Epoch [9/20], Step [100/297], Loss: 0.0548\n","Epoch [9/20], Step [110/297], Loss: 0.0476\n","Epoch [9/20], Step [120/297], Loss: 0.0947\n","Epoch [9/20], Step [130/297], Loss: 0.0843\n","Epoch [9/20], Step [140/297], Loss: 0.0758\n","Epoch [9/20], Step [150/297], Loss: 0.1170\n","Epoch [9/20], Step [160/297], Loss: 0.0704\n","Epoch [9/20], Step [170/297], Loss: 0.0560\n","Epoch [9/20], Step [180/297], Loss: 0.0667\n","Epoch [9/20], Step [190/297], Loss: 0.0752\n","Epoch [9/20], Step [200/297], Loss: 0.0991\n","Epoch [9/20], Step [210/297], Loss: 0.0554\n","Epoch [9/20], Step [220/297], Loss: 0.0579\n","Epoch [9/20], Step [230/297], Loss: 0.0500\n","Epoch [9/20], Step [240/297], Loss: 0.0794\n","Epoch [9/20], Step [250/297], Loss: 0.0280\n","Epoch [9/20], Step [260/297], Loss: 0.0480\n","Epoch [9/20], Step [270/297], Loss: 0.0977\n","Epoch [9/20], Step [280/297], Loss: 0.0960\n","Epoch [9/20], Step [290/297], Loss: 0.1277\n","Epoch [10/20], Step [10/297], Loss: 0.1018\n","Epoch [10/20], Step [20/297], Loss: 0.0674\n","Epoch [10/20], Step [30/297], Loss: 0.0957\n","Epoch [10/20], Step [40/297], Loss: 0.0838\n","Epoch [10/20], Step [50/297], Loss: 0.1009\n","Epoch [10/20], Step [60/297], Loss: 0.0465\n","Epoch [10/20], Step [70/297], Loss: 0.0851\n","Epoch [10/20], Step [80/297], Loss: 0.0905\n","Epoch [10/20], Step [90/297], Loss: 0.0512\n","Epoch [10/20], Step [100/297], Loss: 0.0451\n","Epoch [10/20], Step [110/297], Loss: 0.0775\n","Epoch [10/20], Step [120/297], Loss: 0.0419\n","Epoch [10/20], Step [130/297], Loss: 0.0654\n","Epoch [10/20], Step [140/297], Loss: 0.0802\n","Epoch [10/20], Step [150/297], Loss: 0.1593\n","Epoch [10/20], Step [160/297], Loss: 0.0478\n","Epoch [10/20], Step [170/297], Loss: 0.1038\n","Epoch [10/20], Step [180/297], Loss: 0.0830\n","Epoch [10/20], Step [190/297], Loss: 0.0373\n","Epoch [10/20], Step [200/297], Loss: 0.0610\n","Epoch [10/20], Step [210/297], Loss: 0.1039\n","Epoch [10/20], Step [220/297], Loss: 0.0934\n","Epoch [10/20], Step [230/297], Loss: 0.0777\n","Epoch [10/20], Step [240/297], Loss: 0.0843\n","Epoch [10/20], Step [250/297], Loss: 0.0848\n","Epoch [10/20], Step [260/297], Loss: 0.0531\n","Epoch [10/20], Step [270/297], Loss: 0.0671\n","Epoch [10/20], Step [280/297], Loss: 0.0580\n","Epoch [10/20], Step [290/297], Loss: 0.0490\n","Epoch [11/20], Step [10/297], Loss: 0.1056\n","Epoch [11/20], Step [20/297], Loss: 0.0625\n","Epoch [11/20], Step [30/297], Loss: 0.0610\n","Epoch [11/20], Step [40/297], Loss: 0.0359\n","Epoch [11/20], Step [50/297], Loss: 0.0720\n","Epoch [11/20], Step [60/297], Loss: 0.0638\n","Epoch [11/20], Step [70/297], Loss: 0.0516\n","Epoch [11/20], Step [80/297], Loss: 0.0953\n","Epoch [11/20], Step [90/297], Loss: 0.0566\n","Epoch [11/20], Step [100/297], Loss: 0.0718\n","Epoch [11/20], Step [110/297], Loss: 0.0905\n","Epoch [11/20], Step [120/297], Loss: 0.0730\n","Epoch [11/20], Step [130/297], Loss: 0.0674\n","Epoch [11/20], Step [140/297], Loss: 0.0811\n","Epoch [11/20], Step [150/297], Loss: 0.0567\n","Epoch [11/20], Step [160/297], Loss: 0.0850\n","Epoch [11/20], Step [170/297], Loss: 0.0613\n","Epoch [11/20], Step [180/297], Loss: 0.0521\n","Epoch [11/20], Step [190/297], Loss: 0.0757\n","Epoch [11/20], Step [200/297], Loss: 0.0630\n","Epoch [11/20], Step [210/297], Loss: 0.1174\n","Epoch [11/20], Step [220/297], Loss: 0.0566\n","Epoch [11/20], Step [230/297], Loss: 0.0605\n","Epoch [11/20], Step [240/297], Loss: 0.0708\n","Epoch [11/20], Step [250/297], Loss: 0.0638\n","Epoch [11/20], Step [260/297], Loss: 0.0857\n","Epoch [11/20], Step [270/297], Loss: 0.0736\n","Epoch [11/20], Step [280/297], Loss: 0.0685\n","Epoch [11/20], Step [290/297], Loss: 0.0473\n","Epoch [12/20], Step [10/297], Loss: 0.0728\n","Epoch [12/20], Step [20/297], Loss: 0.0420\n","Epoch [12/20], Step [30/297], Loss: 0.0767\n","Epoch [12/20], Step [40/297], Loss: 0.0621\n","Epoch [12/20], Step [50/297], Loss: 0.0597\n","Epoch [12/20], Step [60/297], Loss: 0.0808\n","Epoch [12/20], Step [70/297], Loss: 0.0712\n","Epoch [12/20], Step [80/297], Loss: 0.0783\n","Epoch [12/20], Step [90/297], Loss: 0.0454\n","Epoch [12/20], Step [100/297], Loss: 0.0557\n","Epoch [12/20], Step [110/297], Loss: 0.0423\n","Epoch [12/20], Step [120/297], Loss: 0.0657\n","Epoch [12/20], Step [130/297], Loss: 0.0557\n","Epoch [12/20], Step [140/297], Loss: 0.0468\n","Epoch [12/20], Step [150/297], Loss: 0.0613\n","Epoch [12/20], Step [160/297], Loss: 0.0696\n","Epoch [12/20], Step [170/297], Loss: 0.0530\n","Epoch [12/20], Step [180/297], Loss: 0.0880\n","Epoch [12/20], Step [190/297], Loss: 0.0988\n","Epoch [12/20], Step [200/297], Loss: 0.0916\n","Epoch [12/20], Step [210/297], Loss: 0.0303\n","Epoch [12/20], Step [220/297], Loss: 0.0605\n","Epoch [12/20], Step [230/297], Loss: 0.1268\n","Epoch [12/20], Step [240/297], Loss: 0.0382\n","Epoch [12/20], Step [250/297], Loss: 0.0555\n","Epoch [12/20], Step [260/297], Loss: 0.0673\n","Epoch [12/20], Step [270/297], Loss: 0.0668\n","Epoch [12/20], Step [280/297], Loss: 0.0674\n","Epoch [12/20], Step [290/297], Loss: 0.0810\n","Epoch [13/20], Step [10/297], Loss: 0.0592\n","Epoch [13/20], Step [20/297], Loss: 0.0494\n","Epoch [13/20], Step [30/297], Loss: 0.0678\n","Epoch [13/20], Step [40/297], Loss: 0.0718\n","Epoch [13/20], Step [50/297], Loss: 0.0784\n","Epoch [13/20], Step [60/297], Loss: 0.0968\n","Epoch [13/20], Step [70/297], Loss: 0.0731\n","Epoch [13/20], Step [80/297], Loss: 0.0453\n","Epoch [13/20], Step [90/297], Loss: 0.0876\n","Epoch [13/20], Step [100/297], Loss: 0.0714\n","Epoch [13/20], Step [110/297], Loss: 0.0448\n","Epoch [13/20], Step [120/297], Loss: 0.0416\n","Epoch [13/20], Step [130/297], Loss: 0.0306\n","Epoch [13/20], Step [140/297], Loss: 0.1064\n","Epoch [13/20], Step [150/297], Loss: 0.1016\n","Epoch [13/20], Step [160/297], Loss: 0.0561\n","Epoch [13/20], Step [170/297], Loss: 0.0665\n","Epoch [13/20], Step [180/297], Loss: 0.0813\n","Epoch [13/20], Step [190/297], Loss: 0.0867\n","Epoch [13/20], Step [200/297], Loss: 0.0474\n","Epoch [13/20], Step [210/297], Loss: 0.0539\n","Epoch [13/20], Step [220/297], Loss: 0.0658\n","Epoch [13/20], Step [230/297], Loss: 0.1186\n","Epoch [13/20], Step [240/297], Loss: 0.0352\n","Epoch [13/20], Step [250/297], Loss: 0.0515\n","Epoch [13/20], Step [260/297], Loss: 0.0665\n","Epoch [13/20], Step [270/297], Loss: 0.0624\n","Epoch [13/20], Step [280/297], Loss: 0.0650\n","Epoch [13/20], Step [290/297], Loss: 0.0653\n","Epoch [14/20], Step [10/297], Loss: 0.0461\n","Epoch [14/20], Step [20/297], Loss: 0.0334\n","Epoch [14/20], Step [30/297], Loss: 0.0561\n","Epoch [14/20], Step [40/297], Loss: 0.0427\n","Epoch [14/20], Step [50/297], Loss: 0.0555\n","Epoch [14/20], Step [60/297], Loss: 0.1378\n","Epoch [14/20], Step [70/297], Loss: 0.0605\n","Epoch [14/20], Step [80/297], Loss: 0.0432\n","Epoch [14/20], Step [90/297], Loss: 0.0615\n","Epoch [14/20], Step [100/297], Loss: 0.0413\n","Epoch [14/20], Step [110/297], Loss: 0.0656\n","Epoch [14/20], Step [120/297], Loss: 0.0644\n","Epoch [14/20], Step [130/297], Loss: 0.0647\n","Epoch [14/20], Step [140/297], Loss: 0.0394\n","Epoch [14/20], Step [150/297], Loss: 0.0494\n","Epoch [14/20], Step [160/297], Loss: 0.0458\n","Epoch [14/20], Step [170/297], Loss: 0.0799\n","Epoch [14/20], Step [180/297], Loss: 0.0831\n","Epoch [14/20], Step [190/297], Loss: 0.0704\n","Epoch [14/20], Step [200/297], Loss: 0.1016\n","Epoch [14/20], Step [210/297], Loss: 0.0537\n","Epoch [14/20], Step [220/297], Loss: 0.0335\n","Epoch [14/20], Step [230/297], Loss: 0.0368\n","Epoch [14/20], Step [240/297], Loss: 0.0507\n","Epoch [14/20], Step [250/297], Loss: 0.0602\n","Epoch [14/20], Step [260/297], Loss: 0.0586\n","Epoch [14/20], Step [270/297], Loss: 0.0552\n","Epoch [14/20], Step [280/297], Loss: 0.0434\n","Epoch [14/20], Step [290/297], Loss: 0.0451\n","Epoch [15/20], Step [10/297], Loss: 0.0691\n","Epoch [15/20], Step [20/297], Loss: 0.1072\n","Epoch [15/20], Step [30/297], Loss: 0.0507\n","Epoch [15/20], Step [40/297], Loss: 0.0390\n","Epoch [15/20], Step [50/297], Loss: 0.0842\n","Epoch [15/20], Step [60/297], Loss: 0.0345\n","Epoch [15/20], Step [70/297], Loss: 0.0629\n","Epoch [15/20], Step [80/297], Loss: 0.0461\n","Epoch [15/20], Step [90/297], Loss: 0.0809\n","Epoch [15/20], Step [100/297], Loss: 0.0580\n","Epoch [15/20], Step [110/297], Loss: 0.0430\n","Epoch [15/20], Step [120/297], Loss: 0.0445\n","Epoch [15/20], Step [130/297], Loss: 0.0727\n","Epoch [15/20], Step [140/297], Loss: 0.0689\n","Epoch [15/20], Step [150/297], Loss: 0.0938\n","Epoch [15/20], Step [160/297], Loss: 0.0654\n","Epoch [15/20], Step [170/297], Loss: 0.0401\n","Epoch [15/20], Step [180/297], Loss: 0.0597\n","Epoch [15/20], Step [190/297], Loss: 0.0444\n","Epoch [15/20], Step [200/297], Loss: 0.0664\n","Epoch [15/20], Step [210/297], Loss: 0.0828\n","Epoch [15/20], Step [220/297], Loss: 0.0473\n","Epoch [15/20], Step [230/297], Loss: 0.0446\n","Epoch [15/20], Step [240/297], Loss: 0.0735\n","Epoch [15/20], Step [250/297], Loss: 0.0487\n","Epoch [15/20], Step [260/297], Loss: 0.0236\n","Epoch [15/20], Step [270/297], Loss: 0.0484\n","Epoch [15/20], Step [280/297], Loss: 0.1320\n","Epoch [15/20], Step [290/297], Loss: 0.0819\n","Epoch [16/20], Step [10/297], Loss: 0.0654\n","Epoch [16/20], Step [20/297], Loss: 0.1222\n","Epoch [16/20], Step [30/297], Loss: 0.0455\n","Epoch [16/20], Step [40/297], Loss: 0.0650\n","Epoch [16/20], Step [50/297], Loss: 0.0738\n","Epoch [16/20], Step [60/297], Loss: 0.0596\n","Epoch [16/20], Step [70/297], Loss: 0.0740\n","Epoch [16/20], Step [80/297], Loss: 0.0345\n","Epoch [16/20], Step [90/297], Loss: 0.0404\n","Epoch [16/20], Step [100/297], Loss: 0.0441\n","Epoch [16/20], Step [110/297], Loss: 0.0752\n","Epoch [16/20], Step [120/297], Loss: 0.0511\n","Epoch [16/20], Step [130/297], Loss: 0.0304\n","Epoch [16/20], Step [140/297], Loss: 0.0648\n","Epoch [16/20], Step [150/297], Loss: 0.0579\n","Epoch [16/20], Step [160/297], Loss: 0.0558\n","Epoch [16/20], Step [170/297], Loss: 0.0680\n","Epoch [16/20], Step [180/297], Loss: 0.0468\n","Epoch [16/20], Step [190/297], Loss: 0.0387\n","Epoch [16/20], Step [200/297], Loss: 0.0552\n","Epoch [16/20], Step [210/297], Loss: 0.0558\n","Epoch [16/20], Step [220/297], Loss: 0.0328\n","Epoch [16/20], Step [230/297], Loss: 0.0577\n","Epoch [16/20], Step [240/297], Loss: 0.0288\n","Epoch [16/20], Step [250/297], Loss: 0.0576\n","Epoch [16/20], Step [260/297], Loss: 0.0423\n","Epoch [16/20], Step [270/297], Loss: 0.0981\n","Epoch [16/20], Step [280/297], Loss: 0.0862\n","Epoch [16/20], Step [290/297], Loss: 0.0401\n","Epoch [17/20], Step [10/297], Loss: 0.0404\n","Epoch [17/20], Step [20/297], Loss: 0.0379\n","Epoch [17/20], Step [30/297], Loss: 0.0658\n","Epoch [17/20], Step [40/297], Loss: 0.0534\n","Epoch [17/20], Step [50/297], Loss: 0.0452\n","Epoch [17/20], Step [60/297], Loss: 0.0501\n","Epoch [17/20], Step [70/297], Loss: 0.0746\n","Epoch [17/20], Step [80/297], Loss: 0.0344\n","Epoch [17/20], Step [90/297], Loss: 0.0727\n","Epoch [17/20], Step [100/297], Loss: 0.0576\n","Epoch [17/20], Step [110/297], Loss: 0.0255\n","Epoch [17/20], Step [120/297], Loss: 0.0473\n","Epoch [17/20], Step [130/297], Loss: 0.0889\n","Epoch [17/20], Step [140/297], Loss: 0.0345\n","Epoch [17/20], Step [150/297], Loss: 0.0573\n","Epoch [17/20], Step [160/297], Loss: 0.0584\n","Epoch [17/20], Step [170/297], Loss: 0.0618\n","Epoch [17/20], Step [180/297], Loss: 0.0384\n","Epoch [17/20], Step [190/297], Loss: 0.0583\n","Epoch [17/20], Step [200/297], Loss: 0.0597\n","Epoch [17/20], Step [210/297], Loss: 0.0895\n","Epoch [17/20], Step [220/297], Loss: 0.0385\n","Epoch [17/20], Step [230/297], Loss: 0.0334\n","Epoch [17/20], Step [240/297], Loss: 0.1017\n","Epoch [17/20], Step [250/297], Loss: 0.0651\n","Epoch [17/20], Step [260/297], Loss: 0.0456\n","Epoch [17/20], Step [270/297], Loss: 0.1197\n","Epoch [17/20], Step [280/297], Loss: 0.0662\n","Epoch [17/20], Step [290/297], Loss: 0.0786\n","Epoch [18/20], Step [10/297], Loss: 0.0418\n","Epoch [18/20], Step [20/297], Loss: 0.0295\n","Epoch [18/20], Step [30/297], Loss: 0.1025\n","Epoch [18/20], Step [40/297], Loss: 0.0208\n","Epoch [18/20], Step [50/297], Loss: 0.0434\n","Epoch [18/20], Step [60/297], Loss: 0.0554\n","Epoch [18/20], Step [70/297], Loss: 0.0976\n","Epoch [18/20], Step [80/297], Loss: 0.0298\n","Epoch [18/20], Step [90/297], Loss: 0.0565\n","Epoch [18/20], Step [100/297], Loss: 0.0585\n","Epoch [18/20], Step [110/297], Loss: 0.0850\n","Epoch [18/20], Step [120/297], Loss: 0.0487\n","Epoch [18/20], Step [130/297], Loss: 0.0267\n","Epoch [18/20], Step [140/297], Loss: 0.0681\n","Epoch [18/20], Step [150/297], Loss: 0.1057\n","Epoch [18/20], Step [160/297], Loss: 0.0631\n","Epoch [18/20], Step [170/297], Loss: 0.0684\n","Epoch [18/20], Step [180/297], Loss: 0.0338\n","Epoch [18/20], Step [190/297], Loss: 0.0575\n","Epoch [18/20], Step [200/297], Loss: 0.0354\n","Epoch [18/20], Step [210/297], Loss: 0.0962\n","Epoch [18/20], Step [220/297], Loss: 0.0628\n","Epoch [18/20], Step [230/297], Loss: 0.0333\n","Epoch [18/20], Step [240/297], Loss: 0.0522\n","Epoch [18/20], Step [250/297], Loss: 0.0754\n","Epoch [18/20], Step [260/297], Loss: 0.0606\n","Epoch [18/20], Step [270/297], Loss: 0.0367\n","Epoch [18/20], Step [280/297], Loss: 0.1156\n","Epoch [18/20], Step [290/297], Loss: 0.0816\n","Epoch [19/20], Step [10/297], Loss: 0.0578\n","Epoch [19/20], Step [20/297], Loss: 0.0401\n","Epoch [19/20], Step [30/297], Loss: 0.0329\n","Epoch [19/20], Step [40/297], Loss: 0.0677\n","Epoch [19/20], Step [50/297], Loss: 0.0423\n","Epoch [19/20], Step [60/297], Loss: 0.0338\n","Epoch [19/20], Step [70/297], Loss: 0.0329\n","Epoch [19/20], Step [80/297], Loss: 0.0311\n","Epoch [19/20], Step [90/297], Loss: 0.0464\n","Epoch [19/20], Step [100/297], Loss: 0.0550\n","Epoch [19/20], Step [110/297], Loss: 0.0569\n","Epoch [19/20], Step [120/297], Loss: 0.0610\n","Epoch [19/20], Step [130/297], Loss: 0.0259\n","Epoch [19/20], Step [140/297], Loss: 0.0514\n","Epoch [19/20], Step [150/297], Loss: 0.0192\n","Epoch [19/20], Step [160/297], Loss: 0.0800\n","Epoch [19/20], Step [170/297], Loss: 0.0678\n","Epoch [19/20], Step [180/297], Loss: 0.0373\n","Epoch [19/20], Step [190/297], Loss: 0.0576\n","Epoch [19/20], Step [200/297], Loss: 0.0515\n","Epoch [19/20], Step [210/297], Loss: 0.0603\n","Epoch [19/20], Step [220/297], Loss: 0.0588\n","Epoch [19/20], Step [230/297], Loss: 0.0555\n","Epoch [19/20], Step [240/297], Loss: 0.0622\n","Epoch [19/20], Step [250/297], Loss: 0.0867\n","Epoch [19/20], Step [260/297], Loss: 0.0541\n","Epoch [19/20], Step [270/297], Loss: 0.0296\n","Epoch [19/20], Step [280/297], Loss: 0.0652\n","Epoch [19/20], Step [290/297], Loss: 0.0343\n","Epoch [20/20], Step [10/297], Loss: 0.0245\n","Epoch [20/20], Step [20/297], Loss: 0.0632\n","Epoch [20/20], Step [30/297], Loss: 0.0662\n","Epoch [20/20], Step [40/297], Loss: 0.0560\n","Epoch [20/20], Step [50/297], Loss: 0.0399\n","Epoch [20/20], Step [60/297], Loss: 0.0201\n","Epoch [20/20], Step [70/297], Loss: 0.0289\n","Epoch [20/20], Step [80/297], Loss: 0.0404\n","Epoch [20/20], Step [90/297], Loss: 0.0487\n","Epoch [20/20], Step [100/297], Loss: 0.0469\n","Epoch [20/20], Step [110/297], Loss: 0.0360\n","Epoch [20/20], Step [120/297], Loss: 0.0292\n","Epoch [20/20], Step [130/297], Loss: 0.0119\n","Epoch [20/20], Step [140/297], Loss: 0.0552\n","Epoch [20/20], Step [150/297], Loss: 0.0550\n","Epoch [20/20], Step [160/297], Loss: 0.0515\n","Epoch [20/20], Step [170/297], Loss: 0.0685\n","Epoch [20/20], Step [180/297], Loss: 0.0535\n","Epoch [20/20], Step [190/297], Loss: 0.0635\n","Epoch [20/20], Step [200/297], Loss: 0.0426\n","Epoch [20/20], Step [210/297], Loss: 0.0377\n","Epoch [20/20], Step [220/297], Loss: 0.0276\n","Epoch [20/20], Step [230/297], Loss: 0.0195\n","Epoch [20/20], Step [240/297], Loss: 0.0702\n","Epoch [20/20], Step [250/297], Loss: 0.0660\n","Epoch [20/20], Step [260/297], Loss: 0.0872\n","Epoch [20/20], Step [270/297], Loss: 0.0303\n","Epoch [20/20], Step [280/297], Loss: 0.0691\n","Epoch [20/20], Step [290/297], Loss: 0.0565\n","Test Accuracy of the model on the test images: 95.85166948761348 %\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"uSbFXYKyuvA2","colab_type":"code","outputId":"24d7b0ee-82a4-49d3-d82c-1bcbe8f5a2ee","executionInfo":{"status":"ok","timestamp":1590697041406,"user_tz":240,"elapsed":1296,"user":{"displayName":"Lennon Chen","photoUrl":"","userId":"13862195579520938405"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["with torch.no_grad():\n","  correct = 0\n","  total = 0\n","    #kk=0\n","  for images, labels in train_loader:\n","     # kk=kk+1\n","    images = images.to(device)\n","    labels = labels.to(device)\n","    outputs = model(images)\n","    _, predicted = torch.max(outputs.data, 1)\n","    total += labels.size(0)\n","    correct += (predicted == labels.view(-1)).sum().item()\n","  print('Test Accuracy of the model on the test images: {} %'.format(100 * correct / total))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Test Accuracy of the model on the test images: 97.65500323129476 %\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"V9_P6SABOdOw","colab_type":"code","colab":{}},"source":["from sklearn.preprocessing import MinMaxScaler\n","from sklearn.preprocessing import StandardScaler\n","#ss = MinMaxScaler()\n","ss = StandardScaler()\n","x_train = ss.fit_transform(x_train)\n","x_test = ss.fit_transform(x_test)\n","\n","from sklearn.decomposition import PCA\n","pca = PCA(n_components=0.92)\n","pca.fit(x_train)\n","x_train = pca.transform(x_train)  \n","x_test = pca.transform(x_test)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"MLUm8QsFOoTp","colab_type":"code","colab":{}},"source":["from sklearn import neighbors\n","knn = neighbors.KNeighborsClassifier(n_neighbors=7)\n","knn.fit(x_train, y_train)\n","test = knn.predict(x_test)\n","knn.score(x_test, y_test)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"OxlR_u_KX4eE","colab_type":"code","outputId":"c6eafcc5-2785-47c7-e40d-370708d8aff0","executionInfo":{"status":"ok","timestamp":1590698957602,"user_tz":240,"elapsed":417715,"user":{"displayName":"Lennon Chen","photoUrl":"","userId":"13862195579520938405"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from sklearn.neural_network import MLPClassifier\n","clf = MLPClassifier(solver='adam', alpha=0.4, hidden_layer_sizes=(30,21,18,15,9,6),max_iter=500)\n","clf.fit(x_train, y_train)\n","test = clf.predict(x_test)\n","clf.score(x_test, y_test)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.7735651638713649"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"lWp5o9nHjien","colab_type":"code","colab":{}},"source":["from sklearn.svm import SVC\n","svm = SVC(gamma = 'auto')\n","svm.fit(x_train, y_train)\n","test = svm.predict(x_test)\n","svm.score(x_test, y_test)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"9KW8jbxkjwKc","colab_type":"code","outputId":"0d26b103-3b5c-40a3-f7fa-c3d0b188c3d1","executionInfo":{"status":"ok","timestamp":1590714929300,"user_tz":240,"elapsed":231364,"user":{"displayName":"Lennon Chen","photoUrl":"","userId":"13862195579520938405"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["import sklearn\n","from sklearn.tree import DecisionTreeClassifier\n","nb =sklearn.tree.DecisionTreeClassifier(criterion='entropy',min_samples_split=5)\n","nb.fit(x_train, y_train)\n","\n","test = nb.predict(x_test)\n","nb.score(x_test, y_test)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.8253577473457455"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"eJ45IXTNaoUM","colab_type":"code","colab":{}},"source":["correct0 = 0\n","correct1 = 0\n","correct2 = 0\n","correct3 = 0\n","correct4 = 0\n","for i in range(len(test)):\n","  if test[i] == y_test[i]:\n","    if test[i] == 0:\n","      correct0 += 1\n","    elif test[i] == 1:\n","      correct1 += 1\n","    elif test[i] == 2:\n","      correct2 += 1\n","    elif test[i] == 3:\n","      correct3 += 1\n","    elif test[i] == 4:\n","      correct4 += 1\n","\n","y_test0 = 0\n","y_test1 = 0\n","y_test2 = 0\n","y_test3 = 0\n","y_test4 = 0\n","for i in range(len(y_test)):\n","  if y_test[i] == 0:\n","    y_test0 += 1\n","  elif y_test[i] == 1:\n","    y_test1 += 1\n","  elif y_test[i] == 2:\n","    y_test2 += 1\n","  elif y_test[i] == 3:\n","    y_test3 += 1\n","  elif y_test[i] == 4:\n","    y_test4 += 1\n","\n","print(\"accuracy of 0:\", correct0/y_test0)\n","print(\"accuracy of 1:\", correct1/y_test1)\n","print(\"accuracy of 2:\", correct2/y_test2)\n","print(\"accuracy of 3:\", correct3/y_test3)\n","print(\"accuracy of 4:\", correct4/y_test4)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"jCzGfXGts0PL","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"PnN6JHYpralZ","colab_type":"code","colab":{}},"source":["y_train0 = 0\n","y_train1 = 0\n","y_train2 = 0\n","y_train3 = 0\n","y_train4 = 0\n","for i in range(len(y_train)):\n","  if y_train[i] == 0:\n","    y_train0 += 1\n","  elif y_train[i] == 1:\n","    y_train1 += 1\n","  elif y_train[i] == 2:\n","    y_train2 += 1\n","  elif y_train[i] == 3:\n","    y_train3 += 1\n","  elif y_train[i] == 4:\n","    y_train4 += 1\n","\n","\n","print(\"num of 0:\", y_train0)\n","print(\"num of 1:\", y_train1)\n","print(\"num of 2:\", y_train2)\n","print(\"num of 3:\", y_train3)\n","print(\"num of 4:\", y_train4)\n","\n","print(\"num of 0:\", y_test0)\n","print(\"num of 1:\", y_test1)\n","print(\"num of 2:\", y_test2)\n","print(\"num of 3:\", y_test3)\n","print(\"num of 4:\", y_test4)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"kq4NJUApsKhM","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}