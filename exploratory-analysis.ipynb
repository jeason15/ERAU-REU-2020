{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "2.1.0\nDefault GPU Device: /device:GPU:0\n"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from dfply import *\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import *\n",
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import decomposition\n",
    "from sklearn.decomposition import PCA\n",
    "print(tf.__version__)\n",
    "\n",
    "if tf.test.gpu_device_name():\n",
    "   print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))\n",
    "else:\n",
    "   print(\"Please install GPU version of TF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"E:\\\\ProjectData\\\\ERAU-REU\\\\Project-Drone-Behavior\\\\behavior-captures\\\\behavior-signal-multiple-processed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot = df.plot(legend=False)\n",
    "#plot.figure.savefig(\"E:\\\\ProjectData\\\\ERAU-REU\\\\Project-Drone-Behavior\\\\plots\\\\allplot.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot = videoDf.plot(legend=False)\n",
    "#plot.figure.savefig(\"E:\\\\ProjectData\\\\ERAU-REU\\\\Project-Drone-Behavior\\\\plots\\\\allVideoPlot.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df >>= mutate(drone_present = case_when([df.behavior == 'surround','yes'],\n",
    "[df.behavior == 'straight','yes'],\n",
    "[df.behavior == 'noise','no']))\n",
    "presence_labs = df['drone_present']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(3200, 2)"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "values = np.array(presence_labs)\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(values)\n",
    "\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "y = onehot_encoder.fit_transform(integer_encoded)\n",
    "\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = df.drop(['behavior','signal','multiple','drone_present'],axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential(name='test')\n",
    "model.add(Dense(64, activation='relu', input_shape=(1280,)))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(2, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"test\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense (Dense)                (None, 64)                81984     \n_________________________________________________________________\ndense_1 (Dense)              (None, 32)                2080      \n_________________________________________________________________\ndense_2 (Dense)              (None, 2)                 66        \n=================================================================\nTotal params: 84,130\nTrainable params: 84,130\nNon-trainable params: 0\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.build(input_shape=(1280,))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Train on 2048 samples, validate on 512 samples\nEpoch 1/100\n2048/2048 [==============================] - 1s 419us/sample - loss: 0.5959 - accuracy: 0.6340 - val_loss: 0.5769 - val_accuracy: 0.6592\nEpoch 2/100\n2048/2048 [==============================] - 0s 92us/sample - loss: 0.5387 - accuracy: 0.7715 - val_loss: 0.5423 - val_accuracy: 0.8711\nEpoch 3/100\n2048/2048 [==============================] - 0s 93us/sample - loss: 0.5005 - accuracy: 0.8762 - val_loss: 0.5456 - val_accuracy: 0.8594\nEpoch 4/100\n2048/2048 [==============================] - 0s 69us/sample - loss: 0.4499 - accuracy: 0.8755 - val_loss: 0.5112 - val_accuracy: 0.8682\nEpoch 5/100\n2048/2048 [==============================] - 0s 68us/sample - loss: 0.4053 - accuracy: 0.8794 - val_loss: 0.4708 - val_accuracy: 0.8564\nEpoch 6/100\n2048/2048 [==============================] - 0s 70us/sample - loss: 0.3822 - accuracy: 0.8801 - val_loss: 0.4846 - val_accuracy: 0.8721\nEpoch 7/100\n2048/2048 [==============================] - 0s 70us/sample - loss: 0.3576 - accuracy: 0.8784 - val_loss: 0.4482 - val_accuracy: 0.8730\nEpoch 8/100\n2048/2048 [==============================] - 0s 72us/sample - loss: 0.3445 - accuracy: 0.8806 - val_loss: 0.4492 - val_accuracy: 0.8730\nEpoch 9/100\n2048/2048 [==============================] - 0s 69us/sample - loss: 0.3365 - accuracy: 0.8813 - val_loss: 0.4236 - val_accuracy: 0.8477\nEpoch 10/100\n2048/2048 [==============================] - 0s 100us/sample - loss: 0.3265 - accuracy: 0.8794 - val_loss: 0.4209 - val_accuracy: 0.8721\nEpoch 11/100\n2048/2048 [==============================] - 0s 80us/sample - loss: 0.3215 - accuracy: 0.8838 - val_loss: 0.4028 - val_accuracy: 0.8701\nEpoch 12/100\n2048/2048 [==============================] - 0s 70us/sample - loss: 0.3085 - accuracy: 0.8835 - val_loss: 0.3837 - val_accuracy: 0.8701\nEpoch 13/100\n2048/2048 [==============================] - 0s 69us/sample - loss: 0.2911 - accuracy: 0.8901 - val_loss: 0.4003 - val_accuracy: 0.8643\nEpoch 14/100\n2048/2048 [==============================] - 0s 70us/sample - loss: 0.2832 - accuracy: 0.8887 - val_loss: 0.4015 - val_accuracy: 0.8652\nEpoch 15/100\n2048/2048 [==============================] - 0s 74us/sample - loss: 0.2691 - accuracy: 0.8958 - val_loss: 0.4510 - val_accuracy: 0.8633\nEpoch 16/100\n2048/2048 [==============================] - 0s 81us/sample - loss: 0.2799 - accuracy: 0.8879 - val_loss: 0.4571 - val_accuracy: 0.7979\nEpoch 17/100\n2048/2048 [==============================] - 0s 68us/sample - loss: 0.2690 - accuracy: 0.8940 - val_loss: 0.3864 - val_accuracy: 0.8662\nEpoch 18/100\n2048/2048 [==============================] - 0s 108us/sample - loss: 0.2426 - accuracy: 0.9014 - val_loss: 0.4113 - val_accuracy: 0.8730\nEpoch 19/100\n2048/2048 [==============================] - 0s 71us/sample - loss: 0.2330 - accuracy: 0.9087 - val_loss: 0.4697 - val_accuracy: 0.7939\nEpoch 20/100\n2048/2048 [==============================] - 0s 71us/sample - loss: 0.2282 - accuracy: 0.9072 - val_loss: 0.4498 - val_accuracy: 0.8555\nEpoch 21/100\n2048/2048 [==============================] - 0s 73us/sample - loss: 0.2100 - accuracy: 0.9172 - val_loss: 0.4503 - val_accuracy: 0.8252\nEpoch 22/100\n2048/2048 [==============================] - 0s 71us/sample - loss: 0.2140 - accuracy: 0.9167 - val_loss: 0.4600 - val_accuracy: 0.8477\nEpoch 23/100\n2048/2048 [==============================] - 0s 71us/sample - loss: 0.1940 - accuracy: 0.9221 - val_loss: 0.5009 - val_accuracy: 0.8486\nEpoch 24/100\n2048/2048 [==============================] - 0s 70us/sample - loss: 0.2017 - accuracy: 0.9250 - val_loss: 0.4921 - val_accuracy: 0.8672\nEpoch 25/100\n2048/2048 [==============================] - 0s 92us/sample - loss: 0.1970 - accuracy: 0.9263 - val_loss: 0.5081 - val_accuracy: 0.8262\nEpoch 26/100\n2048/2048 [==============================] - 0s 83us/sample - loss: 0.1860 - accuracy: 0.9272 - val_loss: 0.5101 - val_accuracy: 0.8662\nEpoch 27/100\n2048/2048 [==============================] - 0s 70us/sample - loss: 0.1795 - accuracy: 0.9272 - val_loss: 0.4734 - val_accuracy: 0.8535\nEpoch 28/100\n2048/2048 [==============================] - 0s 69us/sample - loss: 0.1726 - accuracy: 0.9373 - val_loss: 0.5310 - val_accuracy: 0.8252\nEpoch 29/100\n2048/2048 [==============================] - 0s 71us/sample - loss: 0.1581 - accuracy: 0.9438 - val_loss: 0.5089 - val_accuracy: 0.8291\nEpoch 30/100\n2048/2048 [==============================] - 0s 70us/sample - loss: 0.1520 - accuracy: 0.9414 - val_loss: 0.5076 - val_accuracy: 0.8408\nEpoch 31/100\n2048/2048 [==============================] - 0s 71us/sample - loss: 0.1393 - accuracy: 0.9526 - val_loss: 0.5410 - val_accuracy: 0.8506\nEpoch 32/100\n2048/2048 [==============================] - 0s 69us/sample - loss: 0.1353 - accuracy: 0.9507 - val_loss: 0.5640 - val_accuracy: 0.8115\nEpoch 33/100\n2048/2048 [==============================] - 0s 102us/sample - loss: 0.1263 - accuracy: 0.9534 - val_loss: 0.5740 - val_accuracy: 0.8438\nEpoch 34/100\n2048/2048 [==============================] - 0s 70us/sample - loss: 0.1215 - accuracy: 0.9570 - val_loss: 0.5822 - val_accuracy: 0.8193\nEpoch 35/100\n2048/2048 [==============================] - 0s 69us/sample - loss: 0.1143 - accuracy: 0.9597 - val_loss: 0.6000 - val_accuracy: 0.8369\nEpoch 36/100\n2048/2048 [==============================] - 0s 75us/sample - loss: 0.1072 - accuracy: 0.9651 - val_loss: 0.6633 - val_accuracy: 0.8135\nEpoch 37/100\n2048/2048 [==============================] - 0s 73us/sample - loss: 0.1109 - accuracy: 0.9634 - val_loss: 0.6327 - val_accuracy: 0.8086\nEpoch 38/100\n2048/2048 [==============================] - 0s 70us/sample - loss: 0.1023 - accuracy: 0.9644 - val_loss: 0.6610 - val_accuracy: 0.8330\nEpoch 39/100\n2048/2048 [==============================] - 0s 70us/sample - loss: 0.1166 - accuracy: 0.9568 - val_loss: 0.6301 - val_accuracy: 0.8369\nEpoch 40/100\n2048/2048 [==============================] - 0s 74us/sample - loss: 0.0874 - accuracy: 0.9758 - val_loss: 0.6707 - val_accuracy: 0.8506\nEpoch 41/100\n2048/2048 [==============================] - 0s 108us/sample - loss: 0.0901 - accuracy: 0.9707 - val_loss: 0.6809 - val_accuracy: 0.8398\nEpoch 42/100\n2048/2048 [==============================] - 0s 69us/sample - loss: 0.1204 - accuracy: 0.9556 - val_loss: 0.6161 - val_accuracy: 0.8291\nEpoch 43/100\n2048/2048 [==============================] - 0s 70us/sample - loss: 0.0891 - accuracy: 0.9729 - val_loss: 0.7552 - val_accuracy: 0.8008\nEpoch 44/100\n2048/2048 [==============================] - 0s 71us/sample - loss: 0.0801 - accuracy: 0.9751 - val_loss: 0.6983 - val_accuracy: 0.8340\nEpoch 45/100\n2048/2048 [==============================] - 0s 69us/sample - loss: 0.0785 - accuracy: 0.9744 - val_loss: 0.6864 - val_accuracy: 0.8281\nEpoch 46/100\n2048/2048 [==============================] - 0s 71us/sample - loss: 0.0638 - accuracy: 0.9846 - val_loss: 0.8314 - val_accuracy: 0.8359\nEpoch 47/100\n2048/2048 [==============================] - 0s 69us/sample - loss: 0.0672 - accuracy: 0.9807 - val_loss: 0.7996 - val_accuracy: 0.8525\nEpoch 48/100\n2048/2048 [==============================] - 0s 88us/sample - loss: 0.0698 - accuracy: 0.9790 - val_loss: 0.8806 - val_accuracy: 0.7725\nEpoch 49/100\n2048/2048 [==============================] - 0s 89us/sample - loss: 0.0672 - accuracy: 0.9795 - val_loss: 0.8049 - val_accuracy: 0.7783\nEpoch 50/100\n2048/2048 [==============================] - 0s 80us/sample - loss: 0.0667 - accuracy: 0.9780 - val_loss: 0.8434 - val_accuracy: 0.8350\nEpoch 51/100\n2048/2048 [==============================] - 0s 68us/sample - loss: 0.0730 - accuracy: 0.9749 - val_loss: 0.7868 - val_accuracy: 0.8398\nEpoch 52/100\n2048/2048 [==============================] - 0s 69us/sample - loss: 0.0671 - accuracy: 0.9814 - val_loss: 0.8913 - val_accuracy: 0.8369\nEpoch 53/100\n2048/2048 [==============================] - 0s 69us/sample - loss: 0.0466 - accuracy: 0.9893 - val_loss: 0.8940 - val_accuracy: 0.8154\nEpoch 54/100\n2048/2048 [==============================] - 0s 70us/sample - loss: 0.0374 - accuracy: 0.9917 - val_loss: 0.8341 - val_accuracy: 0.8291\nEpoch 55/100\n2048/2048 [==============================] - 0s 70us/sample - loss: 0.0382 - accuracy: 0.9893 - val_loss: 0.8699 - val_accuracy: 0.8311\nEpoch 56/100\n2048/2048 [==============================] - 0s 106us/sample - loss: 0.0315 - accuracy: 0.9944 - val_loss: 0.8466 - val_accuracy: 0.8047\nEpoch 57/100\n2048/2048 [==============================] - 0s 75us/sample - loss: 0.0316 - accuracy: 0.9946 - val_loss: 0.9628 - val_accuracy: 0.8350\nEpoch 58/100\n2048/2048 [==============================] - 0s 68us/sample - loss: 0.0271 - accuracy: 0.9934 - val_loss: 0.9420 - val_accuracy: 0.8291\nEpoch 59/100\n2048/2048 [==============================] - 0s 71us/sample - loss: 0.0258 - accuracy: 0.9949 - val_loss: 0.9566 - val_accuracy: 0.8262\nEpoch 60/100\n2048/2048 [==============================] - 0s 68us/sample - loss: 0.0230 - accuracy: 0.9971 - val_loss: 1.0016 - val_accuracy: 0.8291\nEpoch 61/100\n2048/2048 [==============================] - 0s 70us/sample - loss: 0.0218 - accuracy: 0.9963 - val_loss: 1.0001 - val_accuracy: 0.8311\nEpoch 62/100\n2048/2048 [==============================] - 0s 71us/sample - loss: 0.0219 - accuracy: 0.9971 - val_loss: 1.0647 - val_accuracy: 0.8145\nEpoch 63/100\n2048/2048 [==============================] - 0s 73us/sample - loss: 0.0171 - accuracy: 0.9990 - val_loss: 1.0892 - val_accuracy: 0.8037\nEpoch 64/100\n2048/2048 [==============================] - 0s 108us/sample - loss: 0.0170 - accuracy: 0.9983 - val_loss: 1.0861 - val_accuracy: 0.8047\nEpoch 65/100\n2048/2048 [==============================] - 0s 73us/sample - loss: 0.0158 - accuracy: 0.9990 - val_loss: 1.0141 - val_accuracy: 0.8232\nEpoch 66/100\n2048/2048 [==============================] - 0s 73us/sample - loss: 0.0137 - accuracy: 0.9990 - val_loss: 1.1207 - val_accuracy: 0.8223\nEpoch 67/100\n2048/2048 [==============================] - 0s 71us/sample - loss: 0.0138 - accuracy: 0.9995 - val_loss: 1.0929 - val_accuracy: 0.8262\nEpoch 68/100\n2048/2048 [==============================] - 0s 73us/sample - loss: 0.0111 - accuracy: 0.9995 - val_loss: 1.2215 - val_accuracy: 0.7949\nEpoch 69/100\n2048/2048 [==============================] - 0s 71us/sample - loss: 0.0106 - accuracy: 0.9995 - val_loss: 1.1838 - val_accuracy: 0.8154\nEpoch 70/100\n2048/2048 [==============================] - 0s 71us/sample - loss: 0.0087 - accuracy: 0.9995 - val_loss: 1.1657 - val_accuracy: 0.8193\nEpoch 71/100\n2048/2048 [==============================] - 0s 79us/sample - loss: 0.0088 - accuracy: 0.9995 - val_loss: 1.2767 - val_accuracy: 0.8027\nEpoch 72/100\n2048/2048 [==============================] - 0s 106us/sample - loss: 0.0078 - accuracy: 0.9995 - val_loss: 1.2099 - val_accuracy: 0.7979\nEpoch 73/100\n2048/2048 [==============================] - 0s 69us/sample - loss: 0.0108 - accuracy: 0.9995 - val_loss: 1.2807 - val_accuracy: 0.8105\nEpoch 74/100\n2048/2048 [==============================] - 0s 69us/sample - loss: 0.0070 - accuracy: 0.9995 - val_loss: 1.2780 - val_accuracy: 0.8213\nEpoch 75/100\n2048/2048 [==============================] - 0s 69us/sample - loss: 0.0057 - accuracy: 0.9995 - val_loss: 1.2937 - val_accuracy: 0.8008\nEpoch 76/100\n2048/2048 [==============================] - 0s 72us/sample - loss: 0.0074 - accuracy: 0.9985 - val_loss: 1.4985 - val_accuracy: 0.7656\nEpoch 77/100\n2048/2048 [==============================] - 0s 69us/sample - loss: 0.1698 - accuracy: 0.9475 - val_loss: 0.7618 - val_accuracy: 0.8105\nEpoch 78/100\n2048/2048 [==============================] - 0s 70us/sample - loss: 0.1395 - accuracy: 0.9529 - val_loss: 1.0055 - val_accuracy: 0.8594\nEpoch 79/100\n2048/2048 [==============================] - 0s 81us/sample - loss: 0.0578 - accuracy: 0.9800 - val_loss: 1.0742 - val_accuracy: 0.8213\nEpoch 80/100\n2048/2048 [==============================] - 0s 87us/sample - loss: 0.0529 - accuracy: 0.9814 - val_loss: 1.1641 - val_accuracy: 0.8281\nEpoch 81/100\n2048/2048 [==============================] - 0s 81us/sample - loss: 0.0279 - accuracy: 0.9954 - val_loss: 1.1468 - val_accuracy: 0.8135\nEpoch 82/100\n2048/2048 [==============================] - 0s 71us/sample - loss: 0.0163 - accuracy: 0.9985 - val_loss: 1.1832 - val_accuracy: 0.8320\nEpoch 83/100\n2048/2048 [==============================] - 0s 69us/sample - loss: 0.0208 - accuracy: 0.9978 - val_loss: 1.2255 - val_accuracy: 0.7979\nEpoch 84/100\n2048/2048 [==============================] - 0s 70us/sample - loss: 0.0286 - accuracy: 0.9929 - val_loss: 1.1824 - val_accuracy: 0.8535\nEpoch 85/100\n2048/2048 [==============================] - 0s 70us/sample - loss: 0.0677 - accuracy: 0.9761 - val_loss: 1.0739 - val_accuracy: 0.7832\nEpoch 86/100\n2048/2048 [==============================] - 0s 75us/sample - loss: 0.0232 - accuracy: 0.9944 - val_loss: 1.4377 - val_accuracy: 0.7510\nEpoch 87/100\n2048/2048 [==============================] - 0s 107us/sample - loss: 0.0204 - accuracy: 0.9949 - val_loss: 1.2276 - val_accuracy: 0.8135\nEpoch 88/100\n2048/2048 [==============================] - 0s 70us/sample - loss: 0.0105 - accuracy: 1.0000 - val_loss: 1.2753 - val_accuracy: 0.7871\nEpoch 89/100\n2048/2048 [==============================] - 0s 74us/sample - loss: 0.0094 - accuracy: 0.9990 - val_loss: 1.2995 - val_accuracy: 0.7715\nEpoch 90/100\n2048/2048 [==============================] - 0s 70us/sample - loss: 0.0076 - accuracy: 1.0000 - val_loss: 1.3046 - val_accuracy: 0.8125\nEpoch 91/100\n2048/2048 [==============================] - 0s 69us/sample - loss: 0.0055 - accuracy: 1.0000 - val_loss: 1.2806 - val_accuracy: 0.8203\nEpoch 92/100\n2048/2048 [==============================] - 0s 70us/sample - loss: 0.0053 - accuracy: 1.0000 - val_loss: 1.2889 - val_accuracy: 0.8232\nEpoch 93/100\n2048/2048 [==============================] - 0s 70us/sample - loss: 0.0051 - accuracy: 1.0000 - val_loss: 1.3428 - val_accuracy: 0.8047\nEpoch 94/100\n2048/2048 [==============================] - 0s 76us/sample - loss: 0.0043 - accuracy: 1.0000 - val_loss: 1.3344 - val_accuracy: 0.8213\nEpoch 95/100\n2048/2048 [==============================] - 0s 88us/sample - loss: 0.0041 - accuracy: 1.0000 - val_loss: 1.3517 - val_accuracy: 0.8242\nEpoch 96/100\n2048/2048 [==============================] - 0s 69us/sample - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.3678 - val_accuracy: 0.8203\nEpoch 97/100\n2048/2048 [==============================] - 0s 69us/sample - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.3733 - val_accuracy: 0.8105\nEpoch 98/100\n2048/2048 [==============================] - 0s 71us/sample - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.4122 - val_accuracy: 0.8037\nEpoch 99/100\n2048/2048 [==============================] - 0s 70us/sample - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.4099 - val_accuracy: 0.8115\nEpoch 100/100\n2048/2048 [==============================] - 0s 96us/sample - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.4225 - val_accuracy: 0.8154\n"
    }
   ],
   "source": [
    "fit1 = model.fit(x = x_train,\n",
    "        y = y_train, \n",
    "        epochs = 100,\n",
    "        batch_size = 32,\n",
    "        validation_split = .2,\n",
    "        verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(x_test)\n",
    "prediction_df = pd.DataFrame(prediction, columns=['prob_present','prob_not_present']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "     present  not_present  prob_present  prob_not_present       actual  \\\n0        0.0          1.0      0.000809          0.998866  not_present   \n1        1.0          0.0      0.999988          0.000013      present   \n2        0.0          1.0      0.000180          0.999792  not_present   \n3        0.0          1.0      0.010557          0.987545  not_present   \n4        1.0          0.0      0.999983          0.000019      present   \n..       ...          ...           ...               ...          ...   \n635      0.0          1.0      0.001318          0.998527  not_present   \n636      1.0          0.0      0.999997          0.000004      present   \n637      0.0          1.0      0.000009          0.999986  not_present   \n638      1.0          0.0      0.999998          0.000003      present   \n639      0.0          1.0      0.000031          0.999965  not_present   \n\n       predicted correct  \n0    not_present     yes  \n1        present     yes  \n2    not_present     yes  \n3    not_present     yes  \n4        present     yes  \n..           ...     ...  \n635  not_present     yes  \n636      present     yes  \n637  not_present     yes  \n638      present     yes  \n639  not_present     yes  \n\n[640 rows x 7 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>present</th>\n      <th>not_present</th>\n      <th>prob_present</th>\n      <th>prob_not_present</th>\n      <th>actual</th>\n      <th>predicted</th>\n      <th>correct</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.000809</td>\n      <td>0.998866</td>\n      <td>not_present</td>\n      <td>not_present</td>\n      <td>yes</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.999988</td>\n      <td>0.000013</td>\n      <td>present</td>\n      <td>present</td>\n      <td>yes</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.000180</td>\n      <td>0.999792</td>\n      <td>not_present</td>\n      <td>not_present</td>\n      <td>yes</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.010557</td>\n      <td>0.987545</td>\n      <td>not_present</td>\n      <td>not_present</td>\n      <td>yes</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.999983</td>\n      <td>0.000019</td>\n      <td>present</td>\n      <td>present</td>\n      <td>yes</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>635</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.001318</td>\n      <td>0.998527</td>\n      <td>not_present</td>\n      <td>not_present</td>\n      <td>yes</td>\n    </tr>\n    <tr>\n      <th>636</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.999997</td>\n      <td>0.000004</td>\n      <td>present</td>\n      <td>present</td>\n      <td>yes</td>\n    </tr>\n    <tr>\n      <th>637</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.000009</td>\n      <td>0.999986</td>\n      <td>not_present</td>\n      <td>not_present</td>\n      <td>yes</td>\n    </tr>\n    <tr>\n      <th>638</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.999998</td>\n      <td>0.000003</td>\n      <td>present</td>\n      <td>present</td>\n      <td>yes</td>\n    </tr>\n    <tr>\n      <th>639</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.000031</td>\n      <td>0.999965</td>\n      <td>not_present</td>\n      <td>not_present</td>\n      <td>yes</td>\n    </tr>\n  </tbody>\n</table>\n<p>640 rows × 7 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "y_test = pd.DataFrame(y_test,columns=['present','not_present'])\n",
    "\n",
    "y_pred = y_test >> bind_cols(prediction_df)\n",
    "\n",
    "y_pred >>= mutate(actual = case_when([y_pred.present == 1, 'present'],\n",
    "[y_pred.not_present == 1, 'not_present']),\n",
    "predicted = case_when([y_pred.prob_present > y_pred.prob_not_present, 'present'],\n",
    "[y_pred.prob_present < y_pred.prob_not_present, 'not_present']))\n",
    "\n",
    "y_pred >>= mutate(correct = case_when([y_pred.actual == y_pred.predicted, 'yes'],\n",
    "[y_pred.actual != y_pred.predicted, 'no']))\n",
    "y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"test\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_3 (Dense)              (None, 64)                16448     \n_________________________________________________________________\ndropout (Dropout)            (None, 64)                0         \n_________________________________________________________________\ndense_4 (Dense)              (None, 32)                2080      \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 32)                0         \n_________________________________________________________________\ndense_5 (Dense)              (None, 2)                 66        \n=================================================================\nTotal params: 18,594\nTrainable params: 18,594\nNon-trainable params: 0\n_________________________________________________________________\nTrain on 2048 samples, validate on 512 samples\nEpoch 1/100\n2048/2048 [==============================] - 1s 290us/sample - loss: 0.6878 - accuracy: 0.5298 - val_loss: 0.6810 - val_accuracy: 0.6133\nEpoch 2/100\n2048/2048 [==============================] - 0s 88us/sample - loss: 0.6794 - accuracy: 0.5818 - val_loss: 0.6728 - val_accuracy: 0.6152\nEpoch 3/100\n2048/2048 [==============================] - 0s 77us/sample - loss: 0.6739 - accuracy: 0.5835 - val_loss: 0.6668 - val_accuracy: 0.6152\nEpoch 4/100\n2048/2048 [==============================] - 0s 100us/sample - loss: 0.6697 - accuracy: 0.5840 - val_loss: 0.6618 - val_accuracy: 0.6152\nEpoch 5/100\n2048/2048 [==============================] - 0s 70us/sample - loss: 0.6654 - accuracy: 0.5840 - val_loss: 0.6574 - val_accuracy: 0.6152\nEpoch 6/100\n2048/2048 [==============================] - 0s 70us/sample - loss: 0.6633 - accuracy: 0.5840 - val_loss: 0.6537 - val_accuracy: 0.6152\nEpoch 7/100\n2048/2048 [==============================] - 0s 67us/sample - loss: 0.6608 - accuracy: 0.5840 - val_loss: 0.6502 - val_accuracy: 0.6152\nEpoch 8/100\n2048/2048 [==============================] - 0s 78us/sample - loss: 0.6570 - accuracy: 0.5840 - val_loss: 0.6467 - val_accuracy: 0.6152\nEpoch 9/100\n2048/2048 [==============================] - 0s 71us/sample - loss: 0.6537 - accuracy: 0.5840 - val_loss: 0.6435 - val_accuracy: 0.6152\nEpoch 10/100\n2048/2048 [==============================] - 0s 67us/sample - loss: 0.6505 - accuracy: 0.5840 - val_loss: 0.6407 - val_accuracy: 0.6152\nEpoch 11/100\n2048/2048 [==============================] - 0s 69us/sample - loss: 0.6497 - accuracy: 0.5840 - val_loss: 0.6383 - val_accuracy: 0.6152\nEpoch 12/100\n2048/2048 [==============================] - 0s 103us/sample - loss: 0.6472 - accuracy: 0.5840 - val_loss: 0.6361 - val_accuracy: 0.6152\nEpoch 13/100\n2048/2048 [==============================] - 0s 67us/sample - loss: 0.6442 - accuracy: 0.5840 - val_loss: 0.6336 - val_accuracy: 0.6152\nEpoch 14/100\n2048/2048 [==============================] - 0s 72us/sample - loss: 0.6421 - accuracy: 0.5840 - val_loss: 0.6314 - val_accuracy: 0.6152\nEpoch 15/100\n2048/2048 [==============================] - 0s 71us/sample - loss: 0.6402 - accuracy: 0.5840 - val_loss: 0.6291 - val_accuracy: 0.6152\nEpoch 16/100\n2048/2048 [==============================] - 0s 70us/sample - loss: 0.6404 - accuracy: 0.5840 - val_loss: 0.6270 - val_accuracy: 0.6152\nEpoch 17/100\n2048/2048 [==============================] - 0s 68us/sample - loss: 0.6338 - accuracy: 0.5840 - val_loss: 0.6246 - val_accuracy: 0.6152\nEpoch 18/100\n2048/2048 [==============================] - 0s 68us/sample - loss: 0.6351 - accuracy: 0.5840 - val_loss: 0.6226 - val_accuracy: 0.6152\nEpoch 19/100\n2048/2048 [==============================] - 0s 71us/sample - loss: 0.6321 - accuracy: 0.5840 - val_loss: 0.6203 - val_accuracy: 0.6152\nEpoch 20/100\n2048/2048 [==============================] - 0s 112us/sample - loss: 0.6303 - accuracy: 0.5840 - val_loss: 0.6182 - val_accuracy: 0.6152\nEpoch 21/100\n2048/2048 [==============================] - 0s 72us/sample - loss: 0.6264 - accuracy: 0.5840 - val_loss: 0.6161 - val_accuracy: 0.6152\nEpoch 22/100\n2048/2048 [==============================] - 0s 69us/sample - loss: 0.6258 - accuracy: 0.5840 - val_loss: 0.6140 - val_accuracy: 0.6152\nEpoch 23/100\n2048/2048 [==============================] - 0s 68us/sample - loss: 0.6268 - accuracy: 0.5857 - val_loss: 0.6123 - val_accuracy: 0.6152\nEpoch 24/100\n2048/2048 [==============================] - 0s 68us/sample - loss: 0.6249 - accuracy: 0.5928 - val_loss: 0.6102 - val_accuracy: 0.6162\nEpoch 25/100\n2048/2048 [==============================] - 0s 68us/sample - loss: 0.6212 - accuracy: 0.6013 - val_loss: 0.6083 - val_accuracy: 0.6426\nEpoch 26/100\n2048/2048 [==============================] - 0s 68us/sample - loss: 0.6198 - accuracy: 0.6353 - val_loss: 0.6066 - val_accuracy: 0.6963\nEpoch 27/100\n2048/2048 [==============================] - 0s 79us/sample - loss: 0.6164 - accuracy: 0.6780 - val_loss: 0.6045 - val_accuracy: 0.7090\nEpoch 28/100\n2048/2048 [==============================] - 0s 101us/sample - loss: 0.6162 - accuracy: 0.6963 - val_loss: 0.6026 - val_accuracy: 0.7422\nEpoch 29/100\n2048/2048 [==============================] - 0s 67us/sample - loss: 0.6119 - accuracy: 0.7400 - val_loss: 0.6005 - val_accuracy: 0.7773\nEpoch 30/100\n2048/2048 [==============================] - 0s 70us/sample - loss: 0.6129 - accuracy: 0.7744 - val_loss: 0.5989 - val_accuracy: 0.8184\nEpoch 31/100\n2048/2048 [==============================] - 0s 68us/sample - loss: 0.6081 - accuracy: 0.8052 - val_loss: 0.5969 - val_accuracy: 0.8232\nEpoch 32/100\n2048/2048 [==============================] - 0s 71us/sample - loss: 0.6126 - accuracy: 0.8247 - val_loss: 0.5954 - val_accuracy: 0.8447\nEpoch 33/100\n2048/2048 [==============================] - 0s 72us/sample - loss: 0.6064 - accuracy: 0.8354 - val_loss: 0.5938 - val_accuracy: 0.8584\nEpoch 34/100\n2048/2048 [==============================] - 0s 69us/sample - loss: 0.6041 - accuracy: 0.8530 - val_loss: 0.5921 - val_accuracy: 0.8613\nEpoch 35/100\n2048/2048 [==============================] - 0s 83us/sample - loss: 0.6072 - accuracy: 0.8579 - val_loss: 0.5907 - val_accuracy: 0.8682\nEpoch 36/100\n2048/2048 [==============================] - 0s 84us/sample - loss: 0.6044 - accuracy: 0.8628 - val_loss: 0.5894 - val_accuracy: 0.8730\nEpoch 37/100\n2048/2048 [==============================] - 0s 66us/sample - loss: 0.6003 - accuracy: 0.8652 - val_loss: 0.5878 - val_accuracy: 0.8750\nEpoch 38/100\n2048/2048 [==============================] - 0s 69us/sample - loss: 0.6015 - accuracy: 0.8674 - val_loss: 0.5867 - val_accuracy: 0.8789\nEpoch 39/100\n2048/2048 [==============================] - 0s 71us/sample - loss: 0.5999 - accuracy: 0.8687 - val_loss: 0.5855 - val_accuracy: 0.8789\nEpoch 40/100\n2048/2048 [==============================] - 0s 71us/sample - loss: 0.5977 - accuracy: 0.8713 - val_loss: 0.5841 - val_accuracy: 0.8789\nEpoch 41/100\n2048/2048 [==============================] - 0s 71us/sample - loss: 0.5963 - accuracy: 0.8718 - val_loss: 0.5827 - val_accuracy: 0.8789\nEpoch 42/100\n2048/2048 [==============================] - 0s 72us/sample - loss: 0.5958 - accuracy: 0.8728 - val_loss: 0.5809 - val_accuracy: 0.8789\nEpoch 43/100\n2048/2048 [==============================] - 0s 90us/sample - loss: 0.5950 - accuracy: 0.8728 - val_loss: 0.5797 - val_accuracy: 0.8789\nEpoch 44/100\n2048/2048 [==============================] - 0s 78us/sample - loss: 0.5924 - accuracy: 0.8735 - val_loss: 0.5783 - val_accuracy: 0.8789\nEpoch 45/100\n2048/2048 [==============================] - 0s 69us/sample - loss: 0.5961 - accuracy: 0.8728 - val_loss: 0.5773 - val_accuracy: 0.8789\nEpoch 46/100\n2048/2048 [==============================] - 0s 68us/sample - loss: 0.5869 - accuracy: 0.8728 - val_loss: 0.5759 - val_accuracy: 0.8789\nEpoch 47/100\n2048/2048 [==============================] - 0s 67us/sample - loss: 0.5897 - accuracy: 0.8730 - val_loss: 0.5749 - val_accuracy: 0.8789\nEpoch 48/100\n2048/2048 [==============================] - 0s 68us/sample - loss: 0.5874 - accuracy: 0.8716 - val_loss: 0.5733 - val_accuracy: 0.8789\nEpoch 49/100\n2048/2048 [==============================] - 0s 77us/sample - loss: 0.5812 - accuracy: 0.8723 - val_loss: 0.5718 - val_accuracy: 0.8789\nEpoch 50/100\n2048/2048 [==============================] - 0s 71us/sample - loss: 0.5824 - accuracy: 0.8730 - val_loss: 0.5702 - val_accuracy: 0.8789\nEpoch 51/100\n2048/2048 [==============================] - 0s 94us/sample - loss: 0.5865 - accuracy: 0.8728 - val_loss: 0.5693 - val_accuracy: 0.8789\nEpoch 52/100\n2048/2048 [==============================] - 0s 74us/sample - loss: 0.5801 - accuracy: 0.8723 - val_loss: 0.5676 - val_accuracy: 0.8789\nEpoch 53/100\n2048/2048 [==============================] - 0s 69us/sample - loss: 0.5857 - accuracy: 0.8708 - val_loss: 0.5663 - val_accuracy: 0.8789\nEpoch 54/100\n2048/2048 [==============================] - 0s 69us/sample - loss: 0.5795 - accuracy: 0.8716 - val_loss: 0.5658 - val_accuracy: 0.8789\nEpoch 55/100\n2048/2048 [==============================] - 0s 69us/sample - loss: 0.5840 - accuracy: 0.8701 - val_loss: 0.5635 - val_accuracy: 0.8789\nEpoch 56/100\n2048/2048 [==============================] - 0s 67us/sample - loss: 0.5762 - accuracy: 0.8726 - val_loss: 0.5620 - val_accuracy: 0.8789\nEpoch 57/100\n2048/2048 [==============================] - 0s 68us/sample - loss: 0.5762 - accuracy: 0.8723 - val_loss: 0.5609 - val_accuracy: 0.8789\nEpoch 58/100\n2048/2048 [==============================] - 0s 68us/sample - loss: 0.5751 - accuracy: 0.8730 - val_loss: 0.5590 - val_accuracy: 0.8789\nEpoch 59/100\n2048/2048 [==============================] - 0s 90us/sample - loss: 0.5781 - accuracy: 0.8691 - val_loss: 0.5578 - val_accuracy: 0.8789\nEpoch 60/100\n2048/2048 [==============================] - 0s 74us/sample - loss: 0.5678 - accuracy: 0.8704 - val_loss: 0.5553 - val_accuracy: 0.8789\nEpoch 61/100\n2048/2048 [==============================] - 0s 68us/sample - loss: 0.5700 - accuracy: 0.8711 - val_loss: 0.5534 - val_accuracy: 0.8789\nEpoch 62/100\n2048/2048 [==============================] - 0s 68us/sample - loss: 0.5670 - accuracy: 0.8735 - val_loss: 0.5515 - val_accuracy: 0.8789\nEpoch 63/100\n2048/2048 [==============================] - 0s 67us/sample - loss: 0.5642 - accuracy: 0.8706 - val_loss: 0.5494 - val_accuracy: 0.8789\nEpoch 64/100\n2048/2048 [==============================] - 0s 75us/sample - loss: 0.5703 - accuracy: 0.8691 - val_loss: 0.5481 - val_accuracy: 0.8789\nEpoch 65/100\n2048/2048 [==============================] - 0s 69us/sample - loss: 0.5607 - accuracy: 0.8726 - val_loss: 0.5458 - val_accuracy: 0.8789\nEpoch 66/100\n2048/2048 [==============================] - 0s 70us/sample - loss: 0.5610 - accuracy: 0.8699 - val_loss: 0.5446 - val_accuracy: 0.8789\nEpoch 67/100\n2048/2048 [==============================] - 0s 103us/sample - loss: 0.5580 - accuracy: 0.8696 - val_loss: 0.5428 - val_accuracy: 0.8789\nEpoch 68/100\n2048/2048 [==============================] - 0s 68us/sample - loss: 0.5526 - accuracy: 0.8674 - val_loss: 0.5400 - val_accuracy: 0.8789\nEpoch 69/100\n2048/2048 [==============================] - 0s 70us/sample - loss: 0.5549 - accuracy: 0.8718 - val_loss: 0.5377 - val_accuracy: 0.8789\nEpoch 70/100\n2048/2048 [==============================] - 0s 70us/sample - loss: 0.5480 - accuracy: 0.8708 - val_loss: 0.5357 - val_accuracy: 0.8789\nEpoch 71/100\n2048/2048 [==============================] - 0s 66us/sample - loss: 0.5488 - accuracy: 0.8708 - val_loss: 0.5336 - val_accuracy: 0.8789\nEpoch 72/100\n2048/2048 [==============================] - 0s 66us/sample - loss: 0.5468 - accuracy: 0.8684 - val_loss: 0.5316 - val_accuracy: 0.8789\nEpoch 73/100\n2048/2048 [==============================] - 0s 67us/sample - loss: 0.5418 - accuracy: 0.8674 - val_loss: 0.5287 - val_accuracy: 0.8789\nEpoch 74/100\n2048/2048 [==============================] - 0s 69us/sample - loss: 0.5420 - accuracy: 0.8704 - val_loss: 0.5266 - val_accuracy: 0.8789\nEpoch 75/100\n2048/2048 [==============================] - 0s 85us/sample - loss: 0.5429 - accuracy: 0.8677 - val_loss: 0.5239 - val_accuracy: 0.8789\nEpoch 76/100\n2048/2048 [==============================] - 0s 74us/sample - loss: 0.5337 - accuracy: 0.8716 - val_loss: 0.5214 - val_accuracy: 0.8789\nEpoch 77/100\n2048/2048 [==============================] - 0s 72us/sample - loss: 0.5292 - accuracy: 0.8704 - val_loss: 0.5191 - val_accuracy: 0.8789\nEpoch 78/100\n2048/2048 [==============================] - 0s 75us/sample - loss: 0.5379 - accuracy: 0.8650 - val_loss: 0.5163 - val_accuracy: 0.8789\nEpoch 79/100\n2048/2048 [==============================] - 0s 73us/sample - loss: 0.5321 - accuracy: 0.8689 - val_loss: 0.5139 - val_accuracy: 0.8789\nEpoch 80/100\n2048/2048 [==============================] - 0s 66us/sample - loss: 0.5245 - accuracy: 0.8682 - val_loss: 0.5109 - val_accuracy: 0.8789\nEpoch 81/100\n2048/2048 [==============================] - 0s 84us/sample - loss: 0.5311 - accuracy: 0.8674 - val_loss: 0.5084 - val_accuracy: 0.8789\nEpoch 82/100\n2048/2048 [==============================] - 0s 77us/sample - loss: 0.5242 - accuracy: 0.8669 - val_loss: 0.5054 - val_accuracy: 0.8789\nEpoch 83/100\n2048/2048 [==============================] - 0s 101us/sample - loss: 0.5226 - accuracy: 0.8701 - val_loss: 0.5026 - val_accuracy: 0.8789\nEpoch 84/100\n2048/2048 [==============================] - 0s 71us/sample - loss: 0.5135 - accuracy: 0.8689 - val_loss: 0.5001 - val_accuracy: 0.8789\nEpoch 85/100\n2048/2048 [==============================] - 0s 69us/sample - loss: 0.5144 - accuracy: 0.8706 - val_loss: 0.4974 - val_accuracy: 0.8789\nEpoch 86/100\n2048/2048 [==============================] - 0s 71us/sample - loss: 0.5198 - accuracy: 0.8674 - val_loss: 0.4946 - val_accuracy: 0.8789\nEpoch 87/100\n2048/2048 [==============================] - 0s 66us/sample - loss: 0.5094 - accuracy: 0.8701 - val_loss: 0.4917 - val_accuracy: 0.8789\nEpoch 88/100\n2048/2048 [==============================] - 0s 71us/sample - loss: 0.5064 - accuracy: 0.8701 - val_loss: 0.4896 - val_accuracy: 0.8789\nEpoch 89/100\n2048/2048 [==============================] - 0s 71us/sample - loss: 0.5062 - accuracy: 0.8689 - val_loss: 0.4868 - val_accuracy: 0.8789\nEpoch 90/100\n2048/2048 [==============================] - 0s 72us/sample - loss: 0.5017 - accuracy: 0.8701 - val_loss: 0.4837 - val_accuracy: 0.8789\nEpoch 91/100\n2048/2048 [==============================] - 0s 95us/sample - loss: 0.4993 - accuracy: 0.8652 - val_loss: 0.4811 - val_accuracy: 0.8789\nEpoch 92/100\n2048/2048 [==============================] - 0s 71us/sample - loss: 0.4972 - accuracy: 0.8704 - val_loss: 0.4786 - val_accuracy: 0.8789\nEpoch 93/100\n2048/2048 [==============================] - 0s 70us/sample - loss: 0.4895 - accuracy: 0.8723 - val_loss: 0.4758 - val_accuracy: 0.8789\nEpoch 94/100\n2048/2048 [==============================] - 0s 70us/sample - loss: 0.4924 - accuracy: 0.8679 - val_loss: 0.4731 - val_accuracy: 0.8789\nEpoch 95/100\n2048/2048 [==============================] - 0s 69us/sample - loss: 0.4851 - accuracy: 0.8716 - val_loss: 0.4705 - val_accuracy: 0.8789\nEpoch 96/100\n2048/2048 [==============================] - 0s 70us/sample - loss: 0.4823 - accuracy: 0.8684 - val_loss: 0.4680 - val_accuracy: 0.8789\nEpoch 97/100\n2048/2048 [==============================] - 0s 70us/sample - loss: 0.4905 - accuracy: 0.8674 - val_loss: 0.4658 - val_accuracy: 0.8789\nEpoch 98/100\n2048/2048 [==============================] - 0s 90us/sample - loss: 0.4906 - accuracy: 0.8716 - val_loss: 0.4639 - val_accuracy: 0.8789\nEpoch 99/100\n2048/2048 [==============================] - 0s 85us/sample - loss: 0.4798 - accuracy: 0.8689 - val_loss: 0.4611 - val_accuracy: 0.8789\nEpoch 100/100\n2048/2048 [==============================] - 0s 69us/sample - loss: 0.4726 - accuracy: 0.8706 - val_loss: 0.4583 - val_accuracy: 0.8789\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "     present  not_present  prob_present  prob_not_present       actual  \\\n0        1.0          0.0      0.651111          0.354068      present   \n1        1.0          0.0      0.719579          0.289029      present   \n2        1.0          0.0      0.732523          0.277580      present   \n3        1.0          0.0      0.733460          0.274875      present   \n4        0.0          1.0      0.189913          0.801245  not_present   \n..       ...          ...           ...               ...          ...   \n635      1.0          0.0      0.708738          0.296693      present   \n636      0.0          1.0      0.330905          0.664005  not_present   \n637      1.0          0.0      0.226199          0.773363      present   \n638      1.0          0.0      0.654341          0.344885      present   \n639      0.0          1.0      0.153511          0.847398  not_present   \n\n       predicted correct  \n0        present     yes  \n1        present     yes  \n2        present     yes  \n3        present     yes  \n4    not_present     yes  \n..           ...     ...  \n635      present     yes  \n636  not_present     yes  \n637  not_present      no  \n638      present     yes  \n639  not_present     yes  \n\n[640 rows x 7 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>present</th>\n      <th>not_present</th>\n      <th>prob_present</th>\n      <th>prob_not_present</th>\n      <th>actual</th>\n      <th>predicted</th>\n      <th>correct</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.651111</td>\n      <td>0.354068</td>\n      <td>present</td>\n      <td>present</td>\n      <td>yes</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.719579</td>\n      <td>0.289029</td>\n      <td>present</td>\n      <td>present</td>\n      <td>yes</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.732523</td>\n      <td>0.277580</td>\n      <td>present</td>\n      <td>present</td>\n      <td>yes</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.733460</td>\n      <td>0.274875</td>\n      <td>present</td>\n      <td>present</td>\n      <td>yes</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.189913</td>\n      <td>0.801245</td>\n      <td>not_present</td>\n      <td>not_present</td>\n      <td>yes</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>635</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.708738</td>\n      <td>0.296693</td>\n      <td>present</td>\n      <td>present</td>\n      <td>yes</td>\n    </tr>\n    <tr>\n      <th>636</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.330905</td>\n      <td>0.664005</td>\n      <td>not_present</td>\n      <td>not_present</td>\n      <td>yes</td>\n    </tr>\n    <tr>\n      <th>637</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.226199</td>\n      <td>0.773363</td>\n      <td>present</td>\n      <td>not_present</td>\n      <td>no</td>\n    </tr>\n    <tr>\n      <th>638</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.654341</td>\n      <td>0.344885</td>\n      <td>present</td>\n      <td>present</td>\n      <td>yes</td>\n    </tr>\n    <tr>\n      <th>639</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.153511</td>\n      <td>0.847398</td>\n      <td>not_present</td>\n      <td>not_present</td>\n      <td>yes</td>\n    </tr>\n  </tbody>\n</table>\n<p>640 rows × 7 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "df_small = df[df.columns[0:256]]\n",
    "df_small >>= bind_cols(df.drone_present)\n",
    "\n",
    "presence_labs = df_small['drone_present']\n",
    "\n",
    "values = np.array(presence_labs)\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(values)\n",
    "\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "y = onehot_encoder.fit_transform(integer_encoded)\n",
    "\n",
    "x = df_small.drop(['drone_present'],axis=1).values\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
    "\n",
    "model = keras.Sequential(name='test')\n",
    "model.add(Dense(64, activation='relu', input_shape=(256,)))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(2, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='sgd', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.build(input_shape=(1280,))\n",
    "model.summary()\n",
    "\n",
    "fit1 = model.fit(x = x_train,\n",
    "        y = y_train, \n",
    "        epochs = 100,\n",
    "        batch_size = 32,\n",
    "        validation_split = .2,\n",
    "        verbose=True)\n",
    "\n",
    "prediction = model.predict(x_test)\n",
    "prediction_df = pd.DataFrame(prediction, columns=['prob_present','prob_not_present']) \n",
    "\n",
    "y_test = pd.DataFrame(y_test,columns=['present','not_present'])\n",
    "\n",
    "y_pred = y_test >> bind_cols(prediction_df)\n",
    "\n",
    "y_pred >>= mutate(actual = case_when([y_pred.present == 1, 'present'],\n",
    "[y_pred.not_present == 1, 'not_present']),\n",
    "predicted = case_when([y_pred.prob_present > y_pred.prob_not_present, 'present'],\n",
    "[y_pred.prob_present < y_pred.prob_not_present, 'not_present']))\n",
    "\n",
    "y_pred >>= mutate(correct = case_when([y_pred.actual == y_pred.predicted, 'yes'],\n",
    "[y_pred.actual != y_pred.predicted, 'no']))\n",
    "y_pred\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-b40055bfa59a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'behavior'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'signal'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'multiple'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'drone_present'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mpca\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdecomposition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPCA\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1280\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mpca\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mx_transformed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpca\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mexplained_variance\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpca\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexplained_variance_ratio_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "x = df.drop(['behavior','signal','multiple','drone_present'],axis=1).values\n",
    "pca = decomposition.PCA(n_components=1280)\n",
    "pca.fit(x)\n",
    "x_transformed = pca.transform(x)\n",
    "explained_variance = pca.explained_variance_ratio_\n",
    "sum(explained_variance[0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop(['behavior','signal','multiple','drone_present'],axis=1).values\n",
    "pca = decomposition.PCA(n_components=200)\n",
    "pca.fit(x)\n",
    "x_transformed = pca.transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"test\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense (Dense)                (None, 64)                12864     \n_________________________________________________________________\ndense_1 (Dense)              (None, 32)                2080      \n_________________________________________________________________\ndense_2 (Dense)              (None, 2)                 66        \n=================================================================\nTotal params: 15,010\nTrainable params: 15,010\nNon-trainable params: 0\n_________________________________________________________________\nTrain on 2048 samples, validate on 512 samples\nEpoch 1/100\n2048/2048 [==============================] - 1s 401us/sample - loss: 0.7015 - accuracy: 0.5771 - val_loss: 0.6896 - val_accuracy: 0.6016\nEpoch 2/100\n2048/2048 [==============================] - 0s 119us/sample - loss: 0.6879 - accuracy: 0.6006 - val_loss: 0.6774 - val_accuracy: 0.6064\nEpoch 3/100\n2048/2048 [==============================] - 0s 112us/sample - loss: 0.6749 - accuracy: 0.6057 - val_loss: 0.6655 - val_accuracy: 0.6074\nEpoch 4/100\n2048/2048 [==============================] - 0s 66us/sample - loss: 0.6631 - accuracy: 0.6074 - val_loss: 0.6548 - val_accuracy: 0.6133\nEpoch 5/100\n2048/2048 [==============================] - 0s 67us/sample - loss: 0.6523 - accuracy: 0.6096 - val_loss: 0.6444 - val_accuracy: 0.6143\nEpoch 6/100\n2048/2048 [==============================] - 0s 70us/sample - loss: 0.6415 - accuracy: 0.6123 - val_loss: 0.6338 - val_accuracy: 0.6162\nEpoch 7/100\n2048/2048 [==============================] - 0s 63us/sample - loss: 0.6306 - accuracy: 0.6169 - val_loss: 0.6232 - val_accuracy: 0.6230\nEpoch 8/100\n2048/2048 [==============================] - 0s 96us/sample - loss: 0.6195 - accuracy: 0.6404 - val_loss: 0.6124 - val_accuracy: 0.6748\nEpoch 9/100\n2048/2048 [==============================] - 0s 63us/sample - loss: 0.6080 - accuracy: 0.6980 - val_loss: 0.6014 - val_accuracy: 0.7109\nEpoch 10/100\n2048/2048 [==============================] - 0s 64us/sample - loss: 0.5966 - accuracy: 0.7339 - val_loss: 0.5907 - val_accuracy: 0.7695\nEpoch 11/100\n2048/2048 [==============================] - 0s 68us/sample - loss: 0.5851 - accuracy: 0.8159 - val_loss: 0.5800 - val_accuracy: 0.8418\nEpoch 12/100\n2048/2048 [==============================] - 0s 61us/sample - loss: 0.5735 - accuracy: 0.8621 - val_loss: 0.5693 - val_accuracy: 0.8643\nEpoch 13/100\n2048/2048 [==============================] - 0s 68us/sample - loss: 0.5619 - accuracy: 0.8726 - val_loss: 0.5588 - val_accuracy: 0.8672\nEpoch 14/100\n2048/2048 [==============================] - 0s 66us/sample - loss: 0.5505 - accuracy: 0.8750 - val_loss: 0.5485 - val_accuracy: 0.8672\nEpoch 15/100\n2048/2048 [==============================] - 0s 62us/sample - loss: 0.5391 - accuracy: 0.8752 - val_loss: 0.5382 - val_accuracy: 0.8672\nEpoch 16/100\n2048/2048 [==============================] - 0s 71us/sample - loss: 0.5277 - accuracy: 0.8752 - val_loss: 0.5281 - val_accuracy: 0.8672\nEpoch 17/100\n2048/2048 [==============================] - 0s 94us/sample - loss: 0.5165 - accuracy: 0.8752 - val_loss: 0.5181 - val_accuracy: 0.8672\nEpoch 18/100\n2048/2048 [==============================] - 0s 99us/sample - loss: 0.5057 - accuracy: 0.8757 - val_loss: 0.5085 - val_accuracy: 0.8672\nEpoch 19/100\n2048/2048 [==============================] - 0s 79us/sample - loss: 0.4951 - accuracy: 0.8757 - val_loss: 0.4992 - val_accuracy: 0.8682\nEpoch 20/100\n2048/2048 [==============================] - 0s 77us/sample - loss: 0.4850 - accuracy: 0.8757 - val_loss: 0.4902 - val_accuracy: 0.8682\nEpoch 21/100\n2048/2048 [==============================] - 0s 103us/sample - loss: 0.4754 - accuracy: 0.8757 - val_loss: 0.4818 - val_accuracy: 0.8682\nEpoch 22/100\n2048/2048 [==============================] - 0s 99us/sample - loss: 0.4664 - accuracy: 0.8757 - val_loss: 0.4739 - val_accuracy: 0.8682\nEpoch 23/100\n2048/2048 [==============================] - 0s 148us/sample - loss: 0.4581 - accuracy: 0.8757 - val_loss: 0.4665 - val_accuracy: 0.8682\nEpoch 24/100\n2048/2048 [==============================] - 0s 101us/sample - loss: 0.4503 - accuracy: 0.8752 - val_loss: 0.4598 - val_accuracy: 0.8682\nEpoch 25/100\n2048/2048 [==============================] - 0s 86us/sample - loss: 0.4433 - accuracy: 0.8743 - val_loss: 0.4536 - val_accuracy: 0.8682\nEpoch 26/100\n2048/2048 [==============================] - 0s 73us/sample - loss: 0.4367 - accuracy: 0.8743 - val_loss: 0.4478 - val_accuracy: 0.8672\nEpoch 27/100\n2048/2048 [==============================] - 0s 69us/sample - loss: 0.4309 - accuracy: 0.8740 - val_loss: 0.4425 - val_accuracy: 0.8672\nEpoch 28/100\n2048/2048 [==============================] - 0s 75us/sample - loss: 0.4255 - accuracy: 0.8738 - val_loss: 0.4377 - val_accuracy: 0.8672\nEpoch 29/100\n2048/2048 [==============================] - 0s 87us/sample - loss: 0.4205 - accuracy: 0.8743 - val_loss: 0.4332 - val_accuracy: 0.8672\nEpoch 30/100\n2048/2048 [==============================] - 0s 99us/sample - loss: 0.4159 - accuracy: 0.8745 - val_loss: 0.4289 - val_accuracy: 0.8672\nEpoch 31/100\n2048/2048 [==============================] - 0s 66us/sample - loss: 0.4115 - accuracy: 0.8735 - val_loss: 0.4249 - val_accuracy: 0.8672\nEpoch 32/100\n2048/2048 [==============================] - 0s 63us/sample - loss: 0.4074 - accuracy: 0.8738 - val_loss: 0.4211 - val_accuracy: 0.8672\nEpoch 33/100\n2048/2048 [==============================] - 0s 68us/sample - loss: 0.4036 - accuracy: 0.8738 - val_loss: 0.4178 - val_accuracy: 0.8672\nEpoch 34/100\n2048/2048 [==============================] - 0s 67us/sample - loss: 0.4000 - accuracy: 0.8733 - val_loss: 0.4145 - val_accuracy: 0.8672\nEpoch 35/100\n2048/2048 [==============================] - 0s 63us/sample - loss: 0.3966 - accuracy: 0.8730 - val_loss: 0.4115 - val_accuracy: 0.8672\nEpoch 36/100\n2048/2048 [==============================] - 0s 68us/sample - loss: 0.3935 - accuracy: 0.8735 - val_loss: 0.4085 - val_accuracy: 0.8672\nEpoch 37/100\n2048/2048 [==============================] - 0s 67us/sample - loss: 0.3906 - accuracy: 0.8728 - val_loss: 0.4060 - val_accuracy: 0.8672\nEpoch 38/100\n2048/2048 [==============================] - 0s 98us/sample - loss: 0.3879 - accuracy: 0.8726 - val_loss: 0.4035 - val_accuracy: 0.8672\nEpoch 39/100\n2048/2048 [==============================] - 0s 70us/sample - loss: 0.3852 - accuracy: 0.8738 - val_loss: 0.4009 - val_accuracy: 0.8672\nEpoch 40/100\n2048/2048 [==============================] - 0s 66us/sample - loss: 0.3828 - accuracy: 0.8728 - val_loss: 0.3987 - val_accuracy: 0.8672\nEpoch 41/100\n2048/2048 [==============================] - 0s 69us/sample - loss: 0.3805 - accuracy: 0.8733 - val_loss: 0.3965 - val_accuracy: 0.8672\nEpoch 42/100\n2048/2048 [==============================] - 0s 69us/sample - loss: 0.3783 - accuracy: 0.8730 - val_loss: 0.3946 - val_accuracy: 0.8682\nEpoch 43/100\n2048/2048 [==============================] - 0s 87us/sample - loss: 0.3763 - accuracy: 0.8735 - val_loss: 0.3928 - val_accuracy: 0.8672\nEpoch 44/100\n2048/2048 [==============================] - 0s 92us/sample - loss: 0.3743 - accuracy: 0.8735 - val_loss: 0.3909 - val_accuracy: 0.8672\nEpoch 45/100\n2048/2048 [==============================] - 0s 147us/sample - loss: 0.3724 - accuracy: 0.8738 - val_loss: 0.3891 - val_accuracy: 0.8672\nEpoch 46/100\n2048/2048 [==============================] - 0s 96us/sample - loss: 0.3706 - accuracy: 0.8733 - val_loss: 0.3875 - val_accuracy: 0.8682\nEpoch 47/100\n2048/2048 [==============================] - 0s 102us/sample - loss: 0.3689 - accuracy: 0.8735 - val_loss: 0.3860 - val_accuracy: 0.8682\nEpoch 48/100\n2048/2048 [==============================] - 0s 94us/sample - loss: 0.3673 - accuracy: 0.8735 - val_loss: 0.3844 - val_accuracy: 0.8672\nEpoch 49/100\n2048/2048 [==============================] - 0s 90us/sample - loss: 0.3658 - accuracy: 0.8728 - val_loss: 0.3834 - val_accuracy: 0.8682\nEpoch 50/100\n2048/2048 [==============================] - 0s 94us/sample - loss: 0.3643 - accuracy: 0.8740 - val_loss: 0.3822 - val_accuracy: 0.8682\nEpoch 51/100\n2048/2048 [==============================] - 0s 128us/sample - loss: 0.3629 - accuracy: 0.8740 - val_loss: 0.3809 - val_accuracy: 0.8691\nEpoch 52/100\n2048/2048 [==============================] - 0s 93us/sample - loss: 0.3616 - accuracy: 0.8743 - val_loss: 0.3798 - val_accuracy: 0.8691\nEpoch 53/100\n2048/2048 [==============================] - 0s 90us/sample - loss: 0.3603 - accuracy: 0.8745 - val_loss: 0.3786 - val_accuracy: 0.8691\nEpoch 54/100\n2048/2048 [==============================] - 0s 74us/sample - loss: 0.3591 - accuracy: 0.8740 - val_loss: 0.3776 - val_accuracy: 0.8691\nEpoch 55/100\n2048/2048 [==============================] - 0s 67us/sample - loss: 0.3580 - accuracy: 0.8743 - val_loss: 0.3767 - val_accuracy: 0.8691\nEpoch 56/100\n2048/2048 [==============================] - 0s 70us/sample - loss: 0.3567 - accuracy: 0.8750 - val_loss: 0.3756 - val_accuracy: 0.8691\nEpoch 57/100\n2048/2048 [==============================] - 0s 62us/sample - loss: 0.3557 - accuracy: 0.8745 - val_loss: 0.3746 - val_accuracy: 0.8691\nEpoch 58/100\n2048/2048 [==============================] - 0s 97us/sample - loss: 0.3547 - accuracy: 0.8748 - val_loss: 0.3737 - val_accuracy: 0.8682\nEpoch 59/100\n2048/2048 [==============================] - 0s 106us/sample - loss: 0.3537 - accuracy: 0.8752 - val_loss: 0.3729 - val_accuracy: 0.8682\nEpoch 60/100\n2048/2048 [==============================] - 0s 78us/sample - loss: 0.3526 - accuracy: 0.8750 - val_loss: 0.3721 - val_accuracy: 0.8682\nEpoch 61/100\n2048/2048 [==============================] - 0s 68us/sample - loss: 0.3517 - accuracy: 0.8745 - val_loss: 0.3713 - val_accuracy: 0.8682\nEpoch 62/100\n2048/2048 [==============================] - 0s 70us/sample - loss: 0.3508 - accuracy: 0.8748 - val_loss: 0.3705 - val_accuracy: 0.8672\nEpoch 63/100\n2048/2048 [==============================] - 0s 72us/sample - loss: 0.3499 - accuracy: 0.8752 - val_loss: 0.3697 - val_accuracy: 0.8662\nEpoch 64/100\n2048/2048 [==============================] - 0s 74us/sample - loss: 0.3490 - accuracy: 0.8748 - val_loss: 0.3690 - val_accuracy: 0.8672\nEpoch 65/100\n2048/2048 [==============================] - 0s 80us/sample - loss: 0.3482 - accuracy: 0.8748 - val_loss: 0.3683 - val_accuracy: 0.8662\nEpoch 66/100\n2048/2048 [==============================] - 0s 83us/sample - loss: 0.3473 - accuracy: 0.8752 - val_loss: 0.3676 - val_accuracy: 0.8672\nEpoch 67/100\n2048/2048 [==============================] - 0s 78us/sample - loss: 0.3465 - accuracy: 0.8757 - val_loss: 0.3669 - val_accuracy: 0.8682\nEpoch 68/100\n2048/2048 [==============================] - 0s 86us/sample - loss: 0.3457 - accuracy: 0.8752 - val_loss: 0.3662 - val_accuracy: 0.8672\nEpoch 69/100\n2048/2048 [==============================] - 0s 86us/sample - loss: 0.3451 - accuracy: 0.8752 - val_loss: 0.3656 - val_accuracy: 0.8672\nEpoch 70/100\n2048/2048 [==============================] - 0s 85us/sample - loss: 0.3443 - accuracy: 0.8748 - val_loss: 0.3650 - val_accuracy: 0.8662\nEpoch 71/100\n2048/2048 [==============================] - 0s 88us/sample - loss: 0.3435 - accuracy: 0.8755 - val_loss: 0.3643 - val_accuracy: 0.8662\nEpoch 72/100\n2048/2048 [==============================] - 0s 141us/sample - loss: 0.3429 - accuracy: 0.8752 - val_loss: 0.3638 - val_accuracy: 0.8662\nEpoch 73/100\n2048/2048 [==============================] - 0s 81us/sample - loss: 0.3422 - accuracy: 0.8765 - val_loss: 0.3632 - val_accuracy: 0.8682\nEpoch 74/100\n2048/2048 [==============================] - 0s 76us/sample - loss: 0.3416 - accuracy: 0.8765 - val_loss: 0.3627 - val_accuracy: 0.8662\nEpoch 75/100\n2048/2048 [==============================] - 0s 72us/sample - loss: 0.3409 - accuracy: 0.8757 - val_loss: 0.3622 - val_accuracy: 0.8672\nEpoch 76/100\n2048/2048 [==============================] - 0s 74us/sample - loss: 0.3403 - accuracy: 0.8762 - val_loss: 0.3617 - val_accuracy: 0.8652\nEpoch 77/100\n2048/2048 [==============================] - 0s 71us/sample - loss: 0.3397 - accuracy: 0.8767 - val_loss: 0.3613 - val_accuracy: 0.8662\nEpoch 78/100\n2048/2048 [==============================] - 0s 62us/sample - loss: 0.3391 - accuracy: 0.8770 - val_loss: 0.3608 - val_accuracy: 0.8643\nEpoch 79/100\n2048/2048 [==============================] - 0s 76us/sample - loss: 0.3385 - accuracy: 0.8762 - val_loss: 0.3604 - val_accuracy: 0.8643\nEpoch 80/100\n2048/2048 [==============================] - 0s 92us/sample - loss: 0.3380 - accuracy: 0.8772 - val_loss: 0.3600 - val_accuracy: 0.8652\nEpoch 81/100\n2048/2048 [==============================] - 0s 69us/sample - loss: 0.3375 - accuracy: 0.8774 - val_loss: 0.3597 - val_accuracy: 0.8643\nEpoch 82/100\n2048/2048 [==============================] - 0s 62us/sample - loss: 0.3370 - accuracy: 0.8772 - val_loss: 0.3593 - val_accuracy: 0.8652\nEpoch 83/100\n2048/2048 [==============================] - 0s 66us/sample - loss: 0.3364 - accuracy: 0.8772 - val_loss: 0.3589 - val_accuracy: 0.8643\nEpoch 84/100\n2048/2048 [==============================] - 0s 69us/sample - loss: 0.3360 - accuracy: 0.8770 - val_loss: 0.3585 - val_accuracy: 0.8643\nEpoch 85/100\n2048/2048 [==============================] - 0s 70us/sample - loss: 0.3356 - accuracy: 0.8770 - val_loss: 0.3582 - val_accuracy: 0.8633\nEpoch 86/100\n2048/2048 [==============================] - 0s 81us/sample - loss: 0.3350 - accuracy: 0.8770 - val_loss: 0.3579 - val_accuracy: 0.8633\nEpoch 87/100\n2048/2048 [==============================] - 0s 92us/sample - loss: 0.3345 - accuracy: 0.8779 - val_loss: 0.3575 - val_accuracy: 0.8633\nEpoch 88/100\n2048/2048 [==============================] - 0s 107us/sample - loss: 0.3341 - accuracy: 0.8767 - val_loss: 0.3572 - val_accuracy: 0.8633\nEpoch 89/100\n2048/2048 [==============================] - 0s 71us/sample - loss: 0.3336 - accuracy: 0.8770 - val_loss: 0.3569 - val_accuracy: 0.8643\nEpoch 90/100\n2048/2048 [==============================] - 0s 70us/sample - loss: 0.3332 - accuracy: 0.8767 - val_loss: 0.3565 - val_accuracy: 0.8643\nEpoch 91/100\n2048/2048 [==============================] - 0s 72us/sample - loss: 0.3328 - accuracy: 0.8770 - val_loss: 0.3563 - val_accuracy: 0.8643\nEpoch 92/100\n2048/2048 [==============================] - 0s 90us/sample - loss: 0.3325 - accuracy: 0.8772 - val_loss: 0.3560 - val_accuracy: 0.8643\nEpoch 93/100\n2048/2048 [==============================] - 0s 71us/sample - loss: 0.3320 - accuracy: 0.8772 - val_loss: 0.3557 - val_accuracy: 0.8623\nEpoch 94/100\n2048/2048 [==============================] - 0s 83us/sample - loss: 0.3315 - accuracy: 0.8770 - val_loss: 0.3554 - val_accuracy: 0.8623\nEpoch 95/100\n2048/2048 [==============================] - 0s 111us/sample - loss: 0.3311 - accuracy: 0.8770 - val_loss: 0.3552 - val_accuracy: 0.8633\nEpoch 96/100\n2048/2048 [==============================] - 0s 127us/sample - loss: 0.3308 - accuracy: 0.8779 - val_loss: 0.3549 - val_accuracy: 0.8623\nEpoch 97/100\n2048/2048 [==============================] - 0s 75us/sample - loss: 0.3305 - accuracy: 0.8774 - val_loss: 0.3547 - val_accuracy: 0.8633\nEpoch 98/100\n2048/2048 [==============================] - 0s 71us/sample - loss: 0.3302 - accuracy: 0.8774 - val_loss: 0.3545 - val_accuracy: 0.8633\nEpoch 99/100\n2048/2048 [==============================] - 0s 68us/sample - loss: 0.3298 - accuracy: 0.8772 - val_loss: 0.3542 - val_accuracy: 0.8633\nEpoch 100/100\n2048/2048 [==============================] - 0s 69us/sample - loss: 0.3293 - accuracy: 0.8772 - val_loss: 0.3540 - val_accuracy: 0.8623\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "     present  not_present  prob_present  prob_not_present       actual  \\\n0        0.0          1.0      0.221175          0.795103  not_present   \n1        1.0          0.0      0.985750          0.014067      present   \n2        1.0          0.0      0.979317          0.020947      present   \n3        0.0          1.0      0.186501          0.821260  not_present   \n4        0.0          1.0      0.116559          0.879242  not_present   \n..       ...          ...           ...               ...          ...   \n635      0.0          1.0      0.183813          0.817890  not_present   \n636      1.0          0.0      0.979033          0.020725      present   \n637      0.0          1.0      0.156652          0.835185  not_present   \n638      1.0          0.0      0.982812          0.017315      present   \n639      0.0          1.0      0.178360          0.829649  not_present   \n\n       predicted correct  \n0    not_present     yes  \n1        present     yes  \n2        present     yes  \n3    not_present     yes  \n4    not_present     yes  \n..           ...     ...  \n635  not_present     yes  \n636      present     yes  \n637  not_present     yes  \n638      present     yes  \n639  not_present     yes  \n\n[640 rows x 7 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>present</th>\n      <th>not_present</th>\n      <th>prob_present</th>\n      <th>prob_not_present</th>\n      <th>actual</th>\n      <th>predicted</th>\n      <th>correct</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.221175</td>\n      <td>0.795103</td>\n      <td>not_present</td>\n      <td>not_present</td>\n      <td>yes</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.985750</td>\n      <td>0.014067</td>\n      <td>present</td>\n      <td>present</td>\n      <td>yes</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.979317</td>\n      <td>0.020947</td>\n      <td>present</td>\n      <td>present</td>\n      <td>yes</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.186501</td>\n      <td>0.821260</td>\n      <td>not_present</td>\n      <td>not_present</td>\n      <td>yes</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.116559</td>\n      <td>0.879242</td>\n      <td>not_present</td>\n      <td>not_present</td>\n      <td>yes</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>635</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.183813</td>\n      <td>0.817890</td>\n      <td>not_present</td>\n      <td>not_present</td>\n      <td>yes</td>\n    </tr>\n    <tr>\n      <th>636</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.979033</td>\n      <td>0.020725</td>\n      <td>present</td>\n      <td>present</td>\n      <td>yes</td>\n    </tr>\n    <tr>\n      <th>637</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.156652</td>\n      <td>0.835185</td>\n      <td>not_present</td>\n      <td>not_present</td>\n      <td>yes</td>\n    </tr>\n    <tr>\n      <th>638</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.982812</td>\n      <td>0.017315</td>\n      <td>present</td>\n      <td>present</td>\n      <td>yes</td>\n    </tr>\n    <tr>\n      <th>639</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.178360</td>\n      <td>0.829649</td>\n      <td>not_present</td>\n      <td>not_present</td>\n      <td>yes</td>\n    </tr>\n  </tbody>\n</table>\n<p>640 rows × 7 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "presence_labs = df['drone_present']\n",
    "\n",
    "pca = decomposition.PCA(n_components=200)\n",
    "pca.fit(x)\n",
    "x = pca.transform(x)\n",
    "\n",
    "values = np.array(presence_labs)\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(values)\n",
    "\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "y = onehot_encoder.fit_transform(integer_encoded)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
    "\n",
    "model = keras.Sequential(name='test')\n",
    "model.add(Dense(64, activation='relu', input_shape=(200,)))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(2, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='sgd', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.build(input_shape=(65,))\n",
    "model.summary()\n",
    "\n",
    "fit1 = model.fit(x = x_train,\n",
    "        y = y_train, \n",
    "        epochs = 100,\n",
    "        batch_size = 32,\n",
    "        validation_split = .2,\n",
    "        verbose=True)\n",
    "\n",
    "prediction = model.predict(x_test)\n",
    "prediction_df = pd.DataFrame(prediction, columns=['prob_present','prob_not_present']) \n",
    "\n",
    "y_test = pd.DataFrame(y_test,columns=['present','not_present'])\n",
    "\n",
    "y_pred = y_test >> bind_cols(prediction_df)\n",
    "\n",
    "y_pred >>= mutate(actual = case_when([y_pred.present == 1, 'present'],\n",
    "[y_pred.not_present == 1, 'not_present']),\n",
    "predicted = case_when([y_pred.prob_present > y_pred.prob_not_present, 'present'],\n",
    "[y_pred.prob_present < y_pred.prob_not_present, 'not_present']))\n",
    "\n",
    "y_pred >>= mutate(correct = case_when([y_pred.actual == y_pred.predicted, 'yes'],\n",
    "[y_pred.actual != y_pred.predicted, 'no']))\n",
    "y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37764bittfgpuconda45a37ab07269429dbc68acdce435ee9a",
   "display_name": "Python 3.7.7 64-bit ('tfgpu': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}